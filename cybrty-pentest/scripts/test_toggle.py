#!/usr/bin/env python3
"""
Simple test script to demonstrate AI provider switching
"""

import os
import sys
from pathlib import Path
import subprocess
import json

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.core.config import ModelConfig
from app.core.model_manager import ModelManager

def main():
    print("üîÑ Testing AI Provider Toggle Functionality")
    print("=" * 50)
    
    # Test 1: Current configuration
    print("\n1Ô∏è‚É£ Current Configuration:")
    config = ModelConfig()
    print(f"   Provider: {config.provider}")
    print(f"   Model: {config.model_name}")
    print(f"   API Base: {config.api_base}")
    
    # Create model manager
    manager = ModelManager(config)
    
    # Test 2: Ollama status
    print("\n2Ô∏è‚É£ Ollama Status:")
    ollama_status = manager.check_ollama_status()
    print(f"   Installed: {'‚úÖ' if ollama_status['installed'] else '‚ùå'}")
    print(f"   Running: {'‚úÖ' if ollama_status['running'] else '‚ùå'}")
    print(f"   Models: {', '.join(ollama_status.get('models', []))}")
    
    # Test 3: Environment variable switching
    print("\n3Ô∏è‚É£ Testing Environment Variable Switching:")
    
    # Switch to OpenAI temporarily
    original_provider = os.environ.get('MODEL_PROVIDER', 'ollama')
    original_model = os.environ.get('OPENAI_MODEL', '')
    
    os.environ['MODEL_PROVIDER'] = 'openai'
    os.environ['OPENAI_MODEL'] = 'gpt-3.5-turbo'
    
    # Create new config with updated environment
    openai_config = ModelConfig()
    
    print(f"   Switched to: {openai_config.provider}")
    print(f"   Model: {openai_config.model_name}")
    print(f"   Requires API Key: {openai_config.provider == 'openai'}")
    
    # Switch back to original
    os.environ['MODEL_PROVIDER'] = original_provider
    if original_model:
        os.environ['OPENAI_MODEL'] = original_model
    else:
        os.environ.pop('OPENAI_MODEL', None)
    
    # Test 4: Model switching within Ollama
    print("\n4Ô∏è‚É£ Testing Ollama Model Switching:")
    
    # Test with different models
    models_to_test = ['deepseek-coder', 'deepseek-r1:1.5b']
    original_ollama_model = os.environ.get('OLLAMA_MODEL', 'deepseek-coder')
    
    for model in models_to_test:
        os.environ['OLLAMA_MODEL'] = model
        test_config = ModelConfig()
        print(f"   Model: {model} -> {test_config.model_name}")
    
    # Restore original
    os.environ['OLLAMA_MODEL'] = original_ollama_model
    
    # Test 5: Real connectivity test
    print("\n5Ô∏è‚É£ Testing Real Connectivity:")
    
    try:
        # Test Ollama connectivity using curl
        result = subprocess.run(
            ['curl', '-s', 'http://localhost:11434/api/version'],
            capture_output=True,
            text=True,
            timeout=5
        )
        if result.returncode == 0 and result.stdout:
            version_data = json.loads(result.stdout)
            print(f"   ‚úÖ Ollama server responding (v{version_data.get('version', 'unknown')})")
        else:
            print("   ‚ùå Ollama server not responding")
    except Exception as e:
        print(f"   ‚ùå Ollama connection failed: {e}")
    
    print("\n6Ô∏è‚É£ Available Toggle Commands:")
    print("   # Switch to OpenAI:")
    print("   export MODEL_PROVIDER=openai")
    print("   export OPENAI_API_KEY=your_key_here")
    print("   export OPENAI_MODEL=gpt-4")
    print()
    print("   # Switch to DeepSeek Coder:")
    print("   export MODEL_PROVIDER=ollama")
    print("   export OLLAMA_MODEL=deepseek-coder")
    print()
    print("   # Switch to DeepSeek R1:")
    print("   export MODEL_PROVIDER=ollama")
    print("   export OLLAMA_MODEL=deepseek-r1:1.5b")
    
    print("\nüéâ Toggle functionality test complete!")

if __name__ == "__main__":
    main()
