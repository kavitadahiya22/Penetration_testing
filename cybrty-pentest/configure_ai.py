#!/usr/bin/env python3
"""
AI Model Configuration Script for Cybrty Pentest Platform
Helps configure OpenAI or Ollama for the penetration testing platform.
"""

import os
import json
import requests
import sys
from typing import Dict, List, Optional
import yaml
from pathlib import Path


class AIModelConfigurator:
    def __init__(self):
        self.config_dir = Path("config")
        self.config_file = self.config_dir / "config.yaml"
        self.env_file = Path(".env")
        
    def check_ollama_status(self) -> Dict:
        """Check Ollama installation and running status."""
        status = {
            "installed": False,
            "running": False,
            "version": "Not found",
            "models": [],
            "errors": []
        }
        
        try:
            # Check if Ollama is running on localhost
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                status["running"] = True
                status["installed"] = True
                data = response.json()
                status["models"] = [model["name"] for model in data.get("models", [])]
                
                # Try to get version
                try:
                    version_response = requests.get("http://localhost:11434/api/version", timeout=5)
                    if version_response.status_code == 200:
                        status["version"] = version_response.json().get("version", "Unknown")
                except:
                    status["version"] = "Running (version unknown)"
            else:
                status["errors"].append(f"Ollama API returned status {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            status["errors"].append("Cannot connect to Ollama on localhost:11434")
        except requests.exceptions.Timeout:
            status["errors"].append("Ollama connection timeout")
        except Exception as e:
            status["errors"].append(f"Ollama check error: {str(e)}")
            
        return status
    
    def check_openai_status(self) -> Dict:
        """Check OpenAI API key and availability."""
        status = {
            "api_key_set": False,
            "api_key_valid": False,
            "models_available": [],
            "errors": []
        }
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            status["errors"].append("OpenAI API key not set in OPENAI_API_KEY")
            return status
            
        status["api_key_set"] = True
        
        try:
            import openai
            client = openai.OpenAI(api_key=api_key)
            
            # Try to list models
            models = client.models.list()
            status["api_key_valid"] = True
            
            # Filter for common models
            model_names = [model.id for model in models.data]
            common_models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]
            status["models_available"] = [m for m in common_models if m in model_names]
            
        except ImportError:
            status["errors"].append("OpenAI package not installed. Run: pip install openai")
        except Exception as e:
            status["errors"].append(f"OpenAI API validation failed: {str(e)}")
            
        return status
    
    def load_current_config(self) -> Dict:
        """Load current configuration."""
        try:
            with open(self.config_file, 'r') as f:
                config = yaml.safe_load(f)
                
            model_config = config.get("model", {})
            return {
                "provider": model_config.get("provider", "ollama"),
                "model_name": model_config.get("model_name", "deepseek-coder"),
                "api_base": model_config.get("api_base", "http://localhost:11434"),
                "requires_api_key": model_config.get("provider") == "openai",
                "timestamp": "2025-08-13T12:26:43.950013"
            }
        except Exception as e:
            return {
                "provider": "unknown",
                "error": str(e),
                "timestamp": "2025-08-13T12:26:43.950013"
            }
    
    def configure_ollama(self, model_name: str = "deepseek-coder") -> bool:
        """Configure system to use Ollama."""
        try:
            with open(self.config_file, 'r') as f:
                config = yaml.safe_load(f)
            
            # Update model configuration
            config["model"]["provider"] = "ollama"
            config["model"]["model_name"] = model_name
            config["model"]["api_base"] = "http://ollama:11434"  # Docker internal
            
            # Write back configuration
            with open(self.config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False)
                
            print(f"âœ… Configured to use Ollama with model: {model_name}")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to configure Ollama: {e}")
            return False
    
    def configure_openai(self, model_name: str = "gpt-4", api_key: Optional[str] = None) -> bool:
        """Configure system to use OpenAI."""
        try:
            # Set API key in environment if provided
            if api_key:
                self._update_env_file("OPENAI_API_KEY", api_key)
                os.environ["OPENAI_API_KEY"] = api_key
                
            with open(self.config_file, 'r') as f:
                config = yaml.safe_load(f)
            
            # Update model configuration
            config["model"]["provider"] = "openai"
            config["model"]["model_name"] = model_name
            config["model"]["api_base"] = "https://api.openai.com/v1"
            
            # Write back configuration
            with open(self.config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False)
                
            print(f"âœ… Configured to use OpenAI with model: {model_name}")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to configure OpenAI: {e}")
            return False
    
    def _update_env_file(self, key: str, value: str):
        """Update .env file with new value."""
        env_content = []
        key_found = False
        
        if self.env_file.exists():
            with open(self.env_file, 'r') as f:
                for line in f:
                    if line.strip().startswith(f"{key}="):
                        env_content.append(f"{key}={value}\n")
                        key_found = True
                    else:
                        env_content.append(line)
        
        if not key_found:
            env_content.append(f"{key}={value}\n")
            
        with open(self.env_file, 'w') as f:
            f.writelines(env_content)
    
    def install_ollama_model(self, model_name: str) -> bool:
        """Install/pull a model in Ollama."""
        try:
            print(f"ðŸ“¥ Pulling Ollama model: {model_name}")
            
            # Use docker exec to pull model in the running container
            os.system(f"docker exec docker-ollama-1 ollama pull {model_name}")
            
            # Verify model was installed
            ollama_status = self.check_ollama_status()
            if model_name in ollama_status["models"] or f"{model_name}:latest" in ollama_status["models"]:
                print(f"âœ… Model {model_name} installed successfully")
                return True
            else:
                print(f"âŒ Model {model_name} installation may have failed")
                return False
                
        except Exception as e:
            print(f"âŒ Failed to install model {model_name}: {e}")
            return False
    
    def get_status_report(self) -> Dict:
        """Generate complete status report."""
        return {
            "ollama": self.check_ollama_status(),
            "openai": self.check_openai_status(),
            "current_config": self.load_current_config(),
            "recommendations": self._generate_recommendations()
        }
    
    def _generate_recommendations(self) -> List[str]:
        """Generate configuration recommendations."""
        recommendations = []
        
        ollama_status = self.check_ollama_status()
        openai_status = self.check_openai_status()
        
        if not ollama_status["running"] and not openai_status["api_key_valid"]:
            recommendations.append("Configure either Ollama or OpenAI for AI functionality")
            
        if ollama_status["running"] and not ollama_status["models"]:
            recommendations.append("Install models in Ollama (e.g., deepseek-coder)")
            
        if not openai_status["api_key_set"]:
            recommendations.append("Set OpenAI API key for cloud AI")
            
        if ollama_status["running"] and ollama_status["models"]:
            recommendations.append("Ollama is ready - configured for local AI")
            
        return recommendations


def main():
    """Main CLI interface."""
    configurator = AIModelConfigurator()
    
    if len(sys.argv) == 1:
        # Show status report
        status = configurator.get_status_report()
        print(json.dumps(status, indent=2))
        return
    
    command = sys.argv[1].lower()
    
    if command == "status":
        status = configurator.get_status_report()
        print(json.dumps(status, indent=2))
        
    elif command == "ollama":
        if len(sys.argv) > 2:
            model_name = sys.argv[2]
        else:
            model_name = "deepseek-coder"
            
        print(f"ðŸ”§ Configuring Ollama with model: {model_name}")
        
        # Check if model exists, if not try to install it
        ollama_status = configurator.check_ollama_status()
        if ollama_status["running"]:
            if model_name not in ollama_status["models"] and f"{model_name}:latest" not in ollama_status["models"]:
                print(f"Model {model_name} not found. Installing...")
                configurator.install_ollama_model(model_name)
            
            configurator.configure_ollama(model_name)
        else:
            print("âŒ Ollama is not running. Please start Ollama service first.")
    
    elif command == "openai":
        if len(sys.argv) > 2:
            api_key = sys.argv[2]
        else:
            api_key = input("Enter OpenAI API key: ").strip()
            
        model_name = sys.argv[3] if len(sys.argv) > 3 else "gpt-4"
        
        print(f"ðŸ”§ Configuring OpenAI with model: {model_name}")
        configurator.configure_openai(model_name, api_key)
        
    elif command == "install":
        if len(sys.argv) < 3:
            print("Usage: python configure_ai.py install <model_name>")
            return
            
        model_name = sys.argv[2]
        configurator.install_ollama_model(model_name)
        
    else:
        print("Usage:")
        print("  python configure_ai.py                    # Show status")
        print("  python configure_ai.py status             # Show detailed status")
        print("  python configure_ai.py ollama [model]     # Configure Ollama")
        print("  python configure_ai.py openai [key] [model] # Configure OpenAI")
        print("  python configure_ai.py install <model>    # Install Ollama model")


if __name__ == "__main__":
    main()
