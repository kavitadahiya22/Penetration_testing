"""Enhanced API endpoints for agent analytics and detailed logging."""

import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any

try:
    from fastapi import APIRouter, HTTPException, Query, Depends
    from pydantic import BaseModel, Field
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    # Create mock classes for development
    class APIRouter:
        def __init__(self, **kwargs): pass
        def get(self, *args, **kwargs): return lambda f: f
        def post(self, *args, **kwargs): return lambda f: f
    
    class HTTPException(Exception):
        def __init__(self, status_code, detail): 
            self.status_code = status_code
            self.detail = detail
    
    class BaseModel:
        def __init__(self, **kwargs): pass
    
    def Query(*args, **kwargs): return None
    def Depends(func): return func
    def Field(*args, **kwargs): return None

try:
    import structlog
    logger = structlog.get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)

from ..core.config import get_settings, Settings
from ..core.enhanced_logger import get_enhanced_opensearch_logger, EnhancedOpenSearchLogger
from ..core.enhanced_crew_executor import create_enhanced_crew_executor, EnhancedCrewExecutor

router = APIRouter(prefix="/api/v1/analytics", tags=["Enhanced Analytics"])


# Response Models
class AgentPerformanceResponse(BaseModel):
    """Agent performance metrics response."""
    agent_id: str
    agent_name: str
    time_range: str
    total_activities: int
    performance_summary: Dict[str, Any]
    recent_metrics: Optional[Dict[str, Any]] = None


class TaskExecutionResponse(BaseModel):
    """Task execution details response."""
    task_execution_id: str
    task_name: str
    agent_name: str
    status: str
    execution_time_ms: int
    findings_count: int
    quality_score: float
    artifacts: List[str]


class SecurityEventResponse(BaseModel):
    """Security event response."""
    event_id: str
    event_type: str
    severity: str
    description: str
    occurred_at: datetime
    auto_resolved: bool
    event_data: Dict[str, Any]


class WorkflowAnalyticsResponse(BaseModel):
    """Comprehensive workflow analytics response."""
    run_id: str
    workflow_summary: Dict[str, Any]
    agent_performance: Dict[str, Any]
    security_events: List[SecurityEventResponse]
    performance_trends: Dict[str, Any]
    quality_metrics: Dict[str, Any]
    generated_at: datetime


class DashboardDataResponse(BaseModel):
    """Dashboard data response."""
    overview: Dict[str, Any]
    agent_summaries: Dict[str, Any]
    recent_activities: List[Dict[str, Any]]
    performance_trends: Dict[str, Any]
    alerts: List[Dict[str, Any]]


# Dependency injection
async def get_enhanced_logger(settings: Settings = Depends(get_settings)) -> EnhancedOpenSearchLogger:
    """Get enhanced OpenSearch logger."""
    return get_enhanced_opensearch_logger(settings)


async def get_enhanced_executor(settings: Settings = Depends(get_settings)) -> EnhancedCrewExecutor:
    """Get enhanced crew executor."""
    return await create_enhanced_crew_executor(settings)


# Endpoints
@router.get("/agents/performance", response_model=List[AgentPerformanceResponse])
async def get_agent_performance_metrics(
    time_range: str = Query("24h", description="Time range for metrics (1h, 24h, 7d, 30d)"),
    agent_name: Optional[str] = Query(None, description="Filter by specific agent"),
    enhanced_logger: EnhancedOpenSearchLogger = Depends(get_enhanced_logger)
):
    """Get performance metrics for all agents or a specific agent."""
    try:
        # Query performance data from OpenSearch
        query = {
            "query": {
                "range": {
                    "measured_at": {
                        "gte": f"now-{time_range}"
                    }
                }
            },
            "size": 1000,
            "sort": [{"measured_at": {"order": "desc"}}]
        }
        
        if agent_name:
            query["query"] = {
                "bool": {
                    "must": [
                        query["query"],
                        {"term": {"agent_name.keyword": agent_name}}
                    ]
                }
            }
        
        performance_data = await enhanced_logger.client.search_documents(
            enhanced_logger.index_agent_performance, query
        )
        
        # Group by agent
        agent_metrics = {}
        for record in performance_data:
            agent = record["agent_name"]
            if agent not in agent_metrics:
                agent_metrics[agent] = []
            agent_metrics[agent].append(record)
        
        # Format response
        response = []
        for agent, metrics in agent_metrics.items():
            latest_metric = metrics[0] if metrics else {}
            
            response.append(AgentPerformanceResponse(
                agent_id=latest_metric.get("agent_id", f"{agent}_unknown"),
                agent_name=agent,
                time_range=time_range,
                total_activities=len(metrics),
                performance_summary={
                    "success_rate": latest_metric.get("success_rate", 0.0),
                    "average_execution_time": latest_metric.get("average_execution_time", 0.0),
                    "findings_per_task": latest_metric.get("findings_per_task", 0.0),
                    "resource_efficiency": latest_metric.get("resource_efficiency", 0.0)
                },
                recent_metrics=latest_metric
            ))
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve agent performance: {str(e)}")


@router.get("/tasks/executions", response_model=List[TaskExecutionResponse])
async def get_task_executions(
    run_id: Optional[str] = Query(None, description="Filter by run ID"),
    agent_name: Optional[str] = Query(None, description="Filter by agent name"),
    status: Optional[str] = Query(None, description="Filter by execution status"),
    limit: int = Query(100, ge=1, le=1000, description="Maximum number of results"),
    enhanced_logger: EnhancedOpenSearchLogger = Depends(get_enhanced_logger)
):
    """Get task execution details with filtering options."""
    try:
        query = {
            "query": {"match_all": {}},
            "size": limit,
            "sort": [{"started_at": {"order": "desc"}}]
        }
        
        # Build filters
        filters = []
        if run_id:
            filters.append({"term": {"run_id.keyword": run_id}})
        if agent_name:
            filters.append({"term": {"assigned_agent_id.keyword": f"{agent_name}_*"}})
        if status:
            filters.append({"term": {"status.keyword": status}})
        
        if filters:
            query["query"] = {"bool": {"must": filters}}
        
        executions = await enhanced_logger.client.search_documents(
            enhanced_logger.index_task_executions, query
        )
        
        # Format response
        response = []
        for execution in executions:
            response.append(TaskExecutionResponse(
                task_execution_id=execution["task_execution_id"],
                task_name=execution["task_name"],
                agent_name=execution.get("assigned_agent_id", "unknown").split("_")[0],
                status=execution["status"],
                execution_time_ms=int((datetime.fromisoformat(execution["ended_at"]) - 
                                     datetime.fromisoformat(execution["started_at"])).total_seconds() * 1000) if execution.get("ended_at") else 0,
                findings_count=execution.get("execution_summary", {}).get("findings_count", 0),
                quality_score=execution.get("quality_score", 0.0),
                artifacts=execution.get("execution_summary", {}).get("artifacts", [])
            ))
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve task executions: {str(e)}")


@router.get("/security/events", response_model=List[SecurityEventResponse])
async def get_security_events(
    run_id: Optional[str] = Query(None, description="Filter by run ID"),
    severity: Optional[str] = Query(None, description="Filter by severity (info, warning, error, critical)"),
    event_type: Optional[str] = Query(None, description="Filter by event type"),
    hours: int = Query(24, ge=1, le=168, description="Hours to look back"),
    enhanced_logger: EnhancedOpenSearchLogger = Depends(get_enhanced_logger)
):
    """Get security events with filtering options."""
    try:
        query = {
            "query": {
                "range": {
                    "occurred_at": {
                        "gte": f"now-{hours}h"
                    }
                }
            },
            "size": 1000,
            "sort": [{"occurred_at": {"order": "desc"}}]
        }
        
        # Build filters
        filters = [query["query"]]
        if run_id:
            filters.append({"term": {"run_id.keyword": run_id}})
        if severity:
            filters.append({"term": {"severity.keyword": severity}})
        if event_type:
            filters.append({"term": {"event_type.keyword": event_type}})
        
        if len(filters) > 1:
            query["query"] = {"bool": {"must": filters}}
        
        events = await enhanced_logger.client.search_documents(
            enhanced_logger.index_security_events, query
        )
        
        # Format response
        response = []
        for event in events:
            response.append(SecurityEventResponse(
                event_id=event["event_id"],
                event_type=event["event_type"],
                severity=event["severity"],
                description=event["event_description"],
                occurred_at=datetime.fromisoformat(event["occurred_at"]),
                auto_resolved=event.get("auto_resolved", False),
                event_data=event.get("event_data", {})
            ))
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve security events: {str(e)}")


@router.get("/workflows/{run_id}/analytics", response_model=WorkflowAnalyticsResponse)
async def get_workflow_analytics(
    run_id: str,
    enhanced_executor: EnhancedCrewExecutor = Depends(get_enhanced_executor)
):
    """Get comprehensive analytics for a specific workflow run."""
    try:
        analytics = await enhanced_executor.get_enhanced_run_analytics(run_id)
        
        if not analytics:
            raise HTTPException(status_code=404, detail=f"Run {run_id} not found")
        
        # Format security events
        security_events = []
        for event in analytics.get("enhanced_analytics", {}).get("security_events", []):
            security_events.append(SecurityEventResponse(
                event_id=event["event_id"],
                event_type=event["event_type"],
                severity=event["severity"],
                description=event["event_description"],
                occurred_at=datetime.fromisoformat(event["occurred_at"]),
                auto_resolved=event.get("auto_resolved", False),
                event_data=event.get("event_data", {})
            ))
        
        return WorkflowAnalyticsResponse(
            run_id=run_id,
            workflow_summary=analytics.get("basic_status", {}),
            agent_performance=analytics.get("enhanced_analytics", {}).get("agent_performance", {}),
            security_events=security_events,
            performance_trends=analytics.get("enhanced_analytics", {}).get("performance_metrics", {}),
            quality_metrics=analytics.get("enhanced_analytics", {}).get("quality_metrics", {}),
            generated_at=datetime.fromisoformat(analytics.get("generated_at", datetime.utcnow().isoformat()))
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve workflow analytics: {str(e)}")


@router.get("/dashboard", response_model=DashboardDataResponse)
async def get_dashboard_data(
    time_range: str = Query("24h", description="Time range for dashboard data"),
    enhanced_logger: EnhancedOpenSearchLogger = Depends(get_enhanced_logger)
):
    """Get comprehensive dashboard data for the security operations center."""
    try:
        # Get overview statistics
        overview_query = {
            "query": {
                "range": {
                    "@timestamp": {
                        "gte": f"now-{time_range}"
                    }
                }
            },
            "aggs": {
                "total_activities": {"value_count": {"field": "activity_id.keyword"}},
                "successful_activities": {
                    "filter": {"term": {"status.keyword": "success"}},
                    "aggs": {"count": {"value_count": {"field": "activity_id.keyword"}}}
                },
                "failed_activities": {
                    "filter": {"term": {"status.keyword": "error"}},
                    "aggs": {"count": {"value_count": {"field": "activity_id.keyword"}}}
                },
                "total_findings": {"sum": {"field": "findings_count"}},
                "avg_execution_time": {"avg": {"field": "execution_time_ms"}},
                "agent_breakdown": {
                    "terms": {"field": "agent_name.keyword", "size": 10}
                }
            }
        }
        
        activities = await enhanced_logger.client.search_documents(
            enhanced_logger.index_agent_activities, overview_query
        )
        
        # Get recent activities
        recent_query = {
            "query": {
                "range": {
                    "@timestamp": {
                        "gte": f"now-{time_range}"
                    }
                }
            },
            "size": 50,
            "sort": [{"@timestamp": {"order": "desc"}}]
        }
        
        recent_activities = await enhanced_logger.client.search_documents(
            enhanced_logger.index_agent_activities, recent_query
        )
        
        # Get security alerts
        alerts_query = {
            "query": {
                "bool": {
                    "must": [
                        {"range": {"occurred_at": {"gte": f"now-{time_range}"}}},
                        {"terms": {"severity.keyword": ["warning", "error", "critical"]}}
                    ]
                }
            },
            "size": 20,
            "sort": [{"occurred_at": {"order": "desc"}}]
        }
        
        alerts = await enhanced_logger.client.search_documents(
            enhanced_logger.index_security_events, alerts_query
        )
        
        # Calculate metrics
        total_activities = len(activities)
        successful_activities = len([a for a in activities if a.get("status") == "success"])
        failed_activities = len([a for a in activities if a.get("status") == "error"])
        total_findings = sum(a.get("findings_count", 0) for a in activities)
        
        avg_execution_time = (
            sum(a.get("execution_time_ms", 0) for a in activities) / total_activities
        ) if total_activities > 0 else 0
        
        # Agent summaries
        agent_summaries = {}
        for activity in activities:
            agent = activity.get("agent_name", "unknown")
            if agent not in agent_summaries:
                agent_summaries[agent] = {
                    "total_tasks": 0,
                    "successful_tasks": 0,
                    "findings": 0,
                    "avg_execution_time": 0
                }
            
            agent_summaries[agent]["total_tasks"] += 1
            if activity.get("status") == "success":
                agent_summaries[agent]["successful_tasks"] += 1
            agent_summaries[agent]["findings"] += activity.get("findings_count", 0)
            agent_summaries[agent]["avg_execution_time"] += activity.get("execution_time_ms", 0)
        
        # Calculate averages
        for agent, summary in agent_summaries.items():
            if summary["total_tasks"] > 0:
                summary["avg_execution_time"] /= summary["total_tasks"]
                summary["success_rate"] = summary["successful_tasks"] / summary["total_tasks"]
        
        return DashboardDataResponse(
            overview={
                "total_activities": total_activities,
                "successful_activities": successful_activities,
                "failed_activities": failed_activities,
                "success_rate": successful_activities / total_activities if total_activities > 0 else 0,
                "total_findings": total_findings,
                "average_execution_time": avg_execution_time,
                "active_agents": len(agent_summaries)
            },
            agent_summaries=agent_summaries,
            recent_activities=[
                {
                    "activity_id": a.get("activity_id"),
                    "agent_name": a.get("agent_name"),
                    "task_name": a.get("task_name"),
                    "status": a.get("status"),
                    "findings_count": a.get("findings_count", 0),
                    "started_at": a.get("started_at"),
                    "execution_time_ms": a.get("execution_time_ms", 0)
                }
                for a in recent_activities[:20]
            ],
            performance_trends={
                "execution_time_trend": "stable",  # Could be calculated from historical data
                "success_rate_trend": "improving" if successful_activities > failed_activities else "declining",
                "findings_trend": "increasing" if total_findings > 0 else "stable"
            },
            alerts=[
                {
                    "event_id": alert.get("event_id"),
                    "event_type": alert.get("event_type"),
                    "severity": alert.get("severity"),
                    "description": alert.get("event_description"),
                    "occurred_at": alert.get("occurred_at"),
                    "run_id": alert.get("run_id")
                }
                for alert in alerts
            ]
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve dashboard data: {str(e)}")


@router.get("/agents/{agent_name}/dashboard")
async def get_agent_dashboard(
    agent_name: str,
    time_range: str = Query("24h", description="Time range for agent data"),
    enhanced_logger: EnhancedOpenSearchLogger = Depends(get_enhanced_logger)
):
    """Get detailed dashboard data for a specific agent."""
    try:
        # Find agent context
        agent_query = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"agent_name.keyword": agent_name}},
                        {"range": {"@timestamp": {"gte": f"now-{time_range}"}}}
                    ]
                }
            },
            "size": 1
        }
        
        agent_activities = await enhanced_logger.client.search_documents(
            enhanced_logger.index_agent_activities, agent_query
        )
        
        if not agent_activities:
            raise HTTPException(status_code=404, detail=f"Agent {agent_name} not found or no recent activity")
        
        agent_id = agent_activities[0].get("agent_id")
        if not agent_id:
            raise HTTPException(status_code=404, detail=f"Agent ID not found for {agent_name}")
        
        # Get comprehensive dashboard data
        dashboard_data = await enhanced_logger.get_agent_dashboard_data(agent_id, time_range)
        
        return dashboard_data
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve agent dashboard: {str(e)}")


@router.post("/reports/generate")
async def generate_security_report(
    run_ids: List[str] = Query(..., description="List of run IDs to include in report"),
    report_type: str = Query("comprehensive", description="Type of report (summary, comprehensive, security)"),
    format: str = Query("json", description="Report format (json, pdf)"),
    enhanced_executor: EnhancedCrewExecutor = Depends(get_enhanced_executor)
):
    """Generate a comprehensive security assessment report."""
    try:
        report_data = {
            "report_id": str(uuid.uuid4()),
            "report_type": report_type,
            "generated_at": datetime.utcnow().isoformat(),
            "runs_analyzed": len(run_ids),
            "executive_summary": {},
            "detailed_findings": {},
            "agent_performance": {},
            "security_events": {},
            "recommendations": []
        }
        
        # Collect data for each run
        all_analytics = []
        for run_id in run_ids:
            try:
                analytics = await enhanced_executor.get_enhanced_run_analytics(run_id)
                if analytics:
                    all_analytics.append(analytics)
            except Exception as e:
                logger.warning(f"Failed to get analytics for run {run_id}: {str(e)}")
        
        if not all_analytics:
            raise HTTPException(status_code=404, detail="No valid run data found")
        
        # Aggregate findings
        total_findings = 0
        severity_distribution = {}
        all_security_events = []
        
        for analytics in all_analytics:
            # Extract findings and events
            quality_metrics = analytics.get("enhanced_analytics", {}).get("quality_metrics", {})
            total_findings += quality_metrics.get("total_findings", 0)
            
            security_events = analytics.get("enhanced_analytics", {}).get("security_events", [])
            all_security_events.extend(security_events)
        
        # Generate executive summary
        report_data["executive_summary"] = {
            "total_runs_analyzed": len(run_ids),
            "total_findings": total_findings,
            "security_events_count": len(all_security_events),
            "overall_success_rate": sum(
                a.get("enhanced_analytics", {}).get("quality_metrics", {}).get("success_rate", 0)
                for a in all_analytics
            ) / len(all_analytics) if all_analytics else 0,
            "high_priority_recommendations": [
                "Review failed security controls",
                "Address authentication weaknesses",
                "Implement network segmentation"
            ]
        }
        
        # Add detailed sections based on report type
        if report_type in ["comprehensive", "security"]:
            report_data["security_events"] = {
                "total_events": len(all_security_events),
                "events_by_severity": {},
                "events_by_type": {},
                "critical_events": [e for e in all_security_events if e.get("severity") == "critical"]
            }
        
        if report_type == "comprehensive":
            report_data["agent_performance"] = {
                "performance_summary": {},
                "top_performing_agents": [],
                "areas_for_improvement": []
            }
        
        return report_data
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate report: {str(e)}")
