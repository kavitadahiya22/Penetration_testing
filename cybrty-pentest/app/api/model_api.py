"""
API endpoints for AI model management and switching.
"""

import os
import json
import subprocess
from typing import Dict, Any, List, Optional
from datetime import datetime
from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field

from app.core.config import get_settings, ModelConfig


router = APIRouter(prefix="/api/v1/models", tags=["AI Models"])


class ModelSwitchRequest(BaseModel):
    """Request model for switching AI providers."""
    provider: str = Field(..., description="AI provider", examples=["ollama", "openai", "azure-openai"])
    model_name: Optional[str] = Field(None, description="Model name", examples=["deepseek-coder", "gpt-4", "gpt-3.5-turbo"])
    api_key: Optional[str] = Field(None, description="API key for cloud providers")
    api_base: Optional[str] = Field(None, description="Custom API base URL")


class ModelStatusResponse(BaseModel):
    """Response model for model status."""
    provider: str
    model_name: str
    api_base: str
    requires_api_key: bool
    api_key_set: bool
    is_available: bool
    timestamp: str
    additional_info: Dict[str, Any] = Field(default_factory=dict)


class ProviderStatusResponse(BaseModel):
    """Response model for provider status."""
    ollama: Dict[str, Any]
    openai: Dict[str, Any]
    current_config: Dict[str, Any]
    recommendations: List[str]


def check_ollama_status() -> Dict[str, Any]:
    """Check Ollama status and available models."""
    try:
        # Check if Ollama is installed
        try:
            version_result = subprocess.run(
                ["ollama", "--version"], 
                capture_output=True, 
                text=True, 
                timeout=5
            )
            installed = version_result.returncode == 0
            version = version_result.stdout.strip() if installed else "Not installed"
        except Exception:
            installed = False
            version = "Not found"
        
        # Check if server is running
        try:
            server_result = subprocess.run(
                ["curl", "-s", "http://localhost:11434/api/version"],
                capture_output=True,
                text=True,
                timeout=5
            )
            running = server_result.returncode == 0
        except Exception:
            running = False
        
        # Get available models
        models = []
        if running:
            try:
                models_result = subprocess.run(
                    ["ollama", "list"],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                if models_result.returncode == 0:
                    lines = models_result.stdout.strip().split('\n')[1:]  # Skip header
                    models = [line.split()[0] for line in lines if line.strip()]
            except Exception:
                pass
        
        return {
            "installed": installed,
            "running": running,
            "version": version,
            "models": models,
            "errors": []
        }
    except Exception as e:
        return {
            "installed": False,
            "running": False,
            "version": "Error",
            "models": [],
            "errors": [str(e)]
        }


def check_openai_status() -> Dict[str, Any]:
    """Check OpenAI API status."""
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        api_key_set = bool(api_key and len(api_key) > 20)
        
        # Basic validation
        api_key_valid = api_key_set and api_key is not None and api_key.startswith("sk-")
        
        # Available models (common ones)
        models_available = []
        if api_key_valid:
            models_available = [
                "gpt-4-turbo-preview",
                "gpt-4",
                "gpt-3.5-turbo",
                "gpt-3.5-turbo-16k"
            ]
        
        errors = []
        if not api_key_set:
            errors.append("OpenAI API key not set in OPENAI_API_KEY")
        elif not api_key_valid:
            errors.append("OpenAI API key format appears invalid")
        
        return {
            "api_key_set": api_key_set,
            "api_key_valid": api_key_valid,
            "models_available": models_available,
            "errors": errors
        }
    except Exception as e:
        return {
            "api_key_set": False,
            "api_key_valid": False,
            "models_available": [],
            "errors": [str(e)]
        }


@router.get("/status", response_model=ProviderStatusResponse)
async def get_model_status():
    """Get comprehensive status of all AI providers."""
    try:
        settings = get_settings()
        
        # Get status for all providers
        ollama_status = check_ollama_status()
        openai_status = check_openai_status()
        
        # Get current configuration
        current_config = {
            "provider": settings.model.provider,
            "model_name": settings.model.model_name,
            "api_base": settings.model.api_base,
            "requires_api_key": settings.model.provider in ["openai", "azure-openai"],
            "timestamp": datetime.utcnow().isoformat()
        }
        
        # Generate recommendations
        recommendations = []
        if not ollama_status.get("running", False):
            recommendations.append("Start Ollama service for local AI")
        if not openai_status.get("api_key_set", False):
            recommendations.append("Set OpenAI API key for cloud AI")
        if ollama_status.get("running", False) and not ollama_status.get("models"):
            recommendations.append("Download Ollama models (deepseek-coder recommended)")
        
        return ProviderStatusResponse(
            ollama=ollama_status,
            openai=openai_status,
            current_config=current_config,
            recommendations=recommendations
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get model status: {str(e)}")


@router.post("/switch", response_model=ModelStatusResponse)
async def switch_model(request: ModelSwitchRequest):
    """Switch to a different AI model provider."""
    try:
        # Validate provider
        valid_providers = ["ollama", "openai", "azure-openai"]
        if request.provider not in valid_providers:
            raise HTTPException(
                status_code=400, 
                detail=f"Invalid provider. Must be one of: {valid_providers}"
            )
        
        # Set environment variables for the switch
        os.environ["MODEL_PROVIDER"] = request.provider
        
        # Set model-specific configurations
        if request.provider == "ollama":
            if request.model_name:
                os.environ["OLLAMA_MODEL"] = request.model_name
            if request.api_base:
                os.environ["OLLAMA_BASE_URL"] = request.api_base
                
        elif request.provider == "openai":
            if request.model_name:
                os.environ["OPENAI_MODEL"] = request.model_name
            if request.api_key:
                os.environ["OPENAI_API_KEY"] = request.api_key
            if request.api_base:
                os.environ["OPENAI_API_BASE"] = request.api_base
                
        elif request.provider == "azure-openai":
            if request.model_name:
                os.environ["AZURE_OPENAI_DEPLOYMENT"] = request.model_name
            if request.api_key:
                os.environ["AZURE_OPENAI_API_KEY"] = request.api_key
            if request.api_base:
                os.environ["AZURE_OPENAI_ENDPOINT"] = request.api_base
        
        # Reload settings with new environment variables
        new_settings = get_settings()
        
        # Test the new configuration
        is_available = False
        if request.provider == "ollama":
            ollama_status = check_ollama_status()
            is_available = ollama_status.get("running", False)
        elif request.provider == "openai":
            openai_status = check_openai_status()
            is_available = openai_status.get("api_key_valid", False)
        
        # Get updated status
        api_key_env = ""
        api_key_set = False
        if new_settings.model.provider == "openai":
            api_key_env = new_settings.model.openai_api_key_env
            api_key_set = bool(os.getenv(api_key_env))
        elif new_settings.model.provider == "azure-openai":
            api_key_env = new_settings.model.azure_openai_api_key_env
            api_key_set = bool(os.getenv(api_key_env))
        
        return ModelStatusResponse(
            provider=new_settings.model.provider,
            model_name=new_settings.model.model_name,
            api_base=new_settings.model.api_base,
            requires_api_key=new_settings.model.provider in ["openai", "azure-openai"],
            api_key_set=api_key_set,
            is_available=is_available,
            timestamp=datetime.utcnow().isoformat(),
            additional_info={"switch_successful": True, "provider_tested": is_available}
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to switch model: {str(e)}")


@router.get("/presets")
async def get_model_presets():
    """Get predefined model configurations for quick switching."""
    return {
        "presets": [
            {
                "name": "DeepSeek Coder (Free)",
                "description": "Local coding assistant - no API key required",
                "provider": "ollama",
                "model_name": "deepseek-coder",
                "api_base": "http://localhost:11434",
                "cost": "free",
                "performance": "good",
                "privacy": "complete"
            },
            {
                "name": "DeepSeek R1 (Free)",
                "description": "Local reasoning model - no API key required",
                "provider": "ollama",
                "model_name": "deepseek-r1:1.5b",
                "api_base": "http://localhost:11434",
                "cost": "free",
                "performance": "good",
                "privacy": "complete"
            },
            {
                "name": "GPT-4 Turbo (Paid)",
                "description": "Latest OpenAI model - requires API key",
                "provider": "openai",
                "model_name": "gpt-4-turbo-preview",
                "api_base": "https://api.openai.com/v1",
                "cost": "high",
                "performance": "excellent",
                "privacy": "cloud"
            },
            {
                "name": "GPT-3.5 Turbo (Paid)",
                "description": "Fast and cost-effective - requires API key",
                "provider": "openai",
                "model_name": "gpt-3.5-turbo",
                "api_base": "https://api.openai.com/v1",
                "cost": "low",
                "performance": "good",
                "privacy": "cloud"
            }
        ],
        "current": {
            "provider": get_settings().model.provider,
            "model_name": get_settings().model.model_name
        }
    }


@router.post("/presets/{preset_name}")
async def apply_preset(preset_name: str):
    """Apply a predefined model configuration."""
    presets = {
        "deepseek-coder": {"provider": "ollama", "model_name": "deepseek-coder"},
        "deepseek-r1": {"provider": "ollama", "model_name": "deepseek-r1:1.5b"},
        "gpt-4-turbo": {"provider": "openai", "model_name": "gpt-4-turbo-preview"},
        "gpt-3.5-turbo": {"provider": "openai", "model_name": "gpt-3.5-turbo"},
    }
    
    if preset_name not in presets:
        raise HTTPException(status_code=404, detail=f"Preset '{preset_name}' not found")
    
    preset = presets[preset_name]
    request = ModelSwitchRequest(**preset)
    
    return await switch_model(request)


# Health check endpoint
@router.get("/health")
async def health_check():
    """Health check for the model API."""
    try:
        settings = get_settings()
        return {
            "status": "healthy",
            "current_provider": settings.model.provider,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }
