"""CrewAI-based pentesting execution orchestrator."""

import asyncio
import json
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional

import structlog
from crewai import Crew, Task

from .config import Settings
from .logger import OpenSearchLogger
from .crew.registry import CrewRegistry

logger = structlog.get_logger(__name__)


class CrewAIPentestExecutor:
    """CrewAI-based pentesting executor that orchestrates multi-agent workflows."""

    def __init__(self, settings: Settings, opensearch_logger: OpenSearchLogger):
        """Initialize the CrewAI executor."""
        self.settings = settings
        self.opensearch_logger = opensearch_logger
        self.crew_registry = CrewRegistry(settings)
        self._active_runs: Dict[str, Dict[str, Any]] = {}

    async def execute_plan(
        self,
        plan: Dict[str, Any],
        tenant_id: str,
        simulate: bool = True
    ) -> str:
        """Execute a pentesting plan using CrewAI agents."""
        run_id = str(uuid.uuid4())
        start_time = datetime.utcnow()
        
        try:
            # Initialize run tracking
            run_data = {
                "run_id": run_id,
                "tenant_id": tenant_id,
                "plan_id": plan.get("plan_id"),
                "status": "running",
                "started_at": start_time,
                "steps": [],
                "current_step": 0,
                "total_steps": len(plan.get("steps", [])),
                "simulate": simulate,
                "artifacts": []
            }
            
            self._active_runs[run_id] = run_data
            
            # Create CrewAI crew from plan
            crew = self.crew_registry.create_crew(plan.get("steps", []))
            
            # Execute crew workflow asynchronously
            asyncio.create_task(self._execute_crew_workflow(crew, plan, run_id, tenant_id))
            
            return run_id
            
        except Exception as e:
            logger.error("CrewAI execution initialization failed", error=str(e), run_id=run_id)
            raise

    async def _execute_crew_workflow(
        self,
        crew: Crew,
        plan: Dict[str, Any],
        run_id: str,
        tenant_id: str
    ) -> None:
        """Execute the CrewAI workflow with proper logging and error handling."""
        started_at = datetime.utcnow()
        
        try:
            # Execute the crew
            logger.info("Starting CrewAI execution", run_id=run_id, agents=len(crew.agents))
            
            # CrewAI execution
            crew_result = crew.kickoff()
            
            # Process and log individual task results
            step_results = []
            total_findings = 0
            max_severity = "info"
            all_artifacts = []
            
            for i, task in enumerate(crew.tasks):
                step_start = datetime.utcnow()
                
                try:
                    # Log step start
                    step_data = {
                        "run_id": run_id,
                        "step_id": f"crew_step_{i+1}",
                        "tenant_id": tenant_id,
                        "agent": getattr(task.agent, 'role', 'unknown'),
                        "tool": self._extract_tool_from_task(task),
                        "status": "running",
                        "params": self._extract_params_from_task(task),
                        "started_at": step_start
                    }
                    
                    # Get task result (this would be populated by CrewAI)
                    task_result = getattr(task, 'output', None) or "Task completed"
                    
                    step_end = datetime.utcnow()
                    duration_ms = int((step_end - step_start).total_seconds() * 1000)
                    
                    # Update step with completion
                    step_data.update({
                        "status": "success",
                        "ended_at": step_end,
                        "duration_ms": duration_ms,
                        "summary": {
                            "output": str(task_result),
                            "agent_role": getattr(task.agent, 'role', 'unknown'),
                            "total_findings": self._count_findings_from_output(str(task_result))
                        },
                        "artifacts": self._extract_artifacts_from_output(str(task_result), run_id, step_data["step_id"])
                    })
                    
                    # Log action to OpenSearch
                    await self.opensearch_logger.log_action(
                        run_id=run_id,
                        step_id=step_data["step_id"],
                        tenant_id=tenant_id,
                        agent=step_data["agent"],
                        tool=step_data["tool"],
                        status=step_data["status"],
                        params=step_data["params"],
                        summary=step_data["summary"],
                        artifacts=step_data["artifacts"],
                        started_at=step_start,
                        ended_at=step_end,
                        duration_ms=duration_ms,
                        error_message=None
                    )
                    
                    step_results.append(step_data)
                    
                    # Aggregate findings
                    step_findings = step_data["summary"].get("total_findings", 0)
                    total_findings += step_findings
                    
                    # Track artifacts
                    for artifact_path in step_data["artifacts"].values():
                        all_artifacts.append(artifact_path)
                    
                    # Determine severity
                    step_severity = self._determine_severity_from_findings(step_findings)
                    if self._severity_level(step_severity) > self._severity_level(max_severity):
                        max_severity = step_severity
                    
                    # Update active run tracking
                    if run_id in self._active_runs:
                        self._active_runs[run_id]["steps"].append(step_data)
                        self._active_runs[run_id]["current_step"] = i + 1
                    
                except Exception as step_error:
                    logger.error("CrewAI step failed", error=str(step_error), step=i)
                    
                    step_end = datetime.utcnow()
                    duration_ms = int((step_end - step_start).total_seconds() * 1000)
                    
                    step_data.update({
                        "status": "error",
                        "ended_at": step_end,
                        "duration_ms": duration_ms,
                        "summary": {"error": str(step_error)},
                        "artifacts": {}
                    })
                    
                    # Log error to OpenSearch
                    await self.opensearch_logger.log_action(
                        run_id=run_id,
                        step_id=step_data["step_id"],
                        tenant_id=tenant_id,
                        agent=step_data["agent"],
                        tool=step_data["tool"],
                        status="error",
                        params=step_data["params"],
                        summary=step_data["summary"],
                        artifacts={},
                        started_at=step_start,
                        ended_at=step_end,
                        duration_ms=duration_ms,
                        error_message=str(step_error)
                    )
                    
                    step_results.append(step_data)
            
            # Mark run as completed
            ended_at = datetime.utcnow()
            duration_ms = int((ended_at - started_at).total_seconds() * 1000)
            
            self._active_runs[run_id]["status"] = "completed"
            self._active_runs[run_id]["ended_at"] = ended_at
            self._active_runs[run_id]["artifacts"] = all_artifacts
            
            # Log run completion to OpenSearch
            await self.opensearch_logger.log_run(
                run_id=run_id,
                tenant_id=tenant_id,
                status="completed",
                plan_id=plan.get("plan_id", ""),
                steps_count=len(step_results),
                started_at=started_at,
                ended_at=ended_at,
                artifacts=all_artifacts,
                summary={
                    "total_findings": total_findings,
                    "severity": max_severity,
                    "duration_ms": duration_ms,
                    "features": self._extract_features_from_plan(plan),
                    "depth": self._extract_depth_from_plan(plan),
                    "simulate": self._active_runs[run_id]["simulate"]
                }
            )
            
            logger.info(
                "Completed CrewAI execution",
                run_id=run_id,
                duration_ms=duration_ms,
                total_findings=total_findings,
                severity=max_severity
            )
            
        except Exception as e:
            logger.error("CrewAI workflow execution failed", error=str(e))
            
            # Mark run as failed
            ended_at = datetime.utcnow()
            duration_ms = int((ended_at - started_at).total_seconds() * 1000)
            
            self._active_runs[run_id]["status"] = "error"
            self._active_runs[run_id]["ended_at"] = ended_at
            self._active_runs[run_id]["error"] = str(e)
            
            # Log run failure to OpenSearch
            await self.opensearch_logger.log_run(
                run_id=run_id,
                tenant_id=tenant_id,
                status="error",
                plan_id=plan.get("plan_id", ""),
                steps_count=0,
                started_at=started_at,
                ended_at=ended_at,
                artifacts=[],
                summary={
                    "error": str(e),
                    "total_findings": 0,
                    "severity": "high",
                    "duration_ms": duration_ms,
                    "features": self._extract_features_from_plan(plan),
                    "depth": self._extract_depth_from_plan(plan),
                    "simulate": self._active_runs[run_id]["simulate"]
                }
            )

    def _extract_tool_from_task(self, task: Task) -> str:
        """Extract tool name from CrewAI task."""
        # This is a simplified extraction - in real implementation,
        # you'd parse the task description or agent tools
        description = getattr(task, 'description', '').lower()
        
        tool_keywords = {
            'nmap': 'nmap',
            'amass': 'amass', 
            'zap': 'zap',
            'sqlmap': 'sqlmap',
            'nikto': 'nikto',
            'hydra': 'hydra',
            'crackmapexec': 'crackmapexec',
            'metasploit': 'metasploit',
            'bloodhound': 'bloodhound',
            'reconnaissance': 'recon',
            'scanning': 'scan',
            'enumeration': 'enum'
        }
        
        for keyword, tool in tool_keywords.items():
            if keyword in description:
                return tool
        
        return 'unknown'

    def _extract_params_from_task(self, task: Task) -> Dict[str, Any]:
        """Extract parameters from CrewAI task."""
        # This would extract actual parameters in a real implementation
        return {
            "description": getattr(task, 'description', ''),
            "expected_output": getattr(task, 'expected_output', ''),
            "agent_role": getattr(task.agent, 'role', 'unknown') if hasattr(task, 'agent') else 'unknown'
        }

    def _count_findings_from_output(self, output: str) -> int:
        """Count findings from task output."""
        # Simple heuristic - count lines that might be findings
        lines = output.split('\n')
        finding_keywords = ['found', 'discovered', 'detected', 'vulnerable', 'open', 'exposed']
        
        count = 0
        for line in lines:
            if any(keyword in line.lower() for keyword in finding_keywords):
                count += 1
        
        return count

    def _extract_artifacts_from_output(self, output: str, run_id: str, step_id: str) -> Dict[str, str]:
        """Extract artifact paths from task output."""
        # In a real implementation, this would parse actual file paths
        # For now, create a placeholder artifact file
        artifact_path = f"{self.settings.artifacts.dir}/{run_id}_{step_id}_output.txt"
        
        try:
            # Write output to artifact file
            with open(artifact_path, 'w') as f:
                f.write(output)
            
            return {"output": artifact_path}
        except Exception as e:
            logger.warning("Failed to create artifact", error=str(e))
            return {}

    def _determine_severity_from_findings(self, findings_count: int) -> str:
        """Determine severity based on findings count."""
        if findings_count > 10:
            return "high"
        elif findings_count > 5:
            return "medium"
        elif findings_count > 0:
            return "low"
        else:
            return "info"

    def _severity_level(self, severity: str) -> int:
        """Convert severity to numeric level for comparison."""
        levels = {"info": 0, "low": 1, "medium": 2, "high": 3, "critical": 4}
        return levels.get(severity, 0)

    def _extract_features_from_plan(self, plan: Dict[str, Any]) -> List[str]:
        """Extract unique features from plan steps."""
        features = set()
        for step in plan.get("steps", []):
            agent = step.get("agent")
            if agent:
                features.add(agent)
        return list(features)

    def _extract_depth_from_plan(self, plan: Dict[str, Any]) -> str:
        """Extract depth from plan based on step count."""
        step_count = len(plan.get("steps", []))
        if step_count <= 4:
            return "quick"
        elif step_count <= 8:
            return "standard"
        else:
            return "deep"

    def get_run_status(self, run_id: str) -> Optional[Dict[str, Any]]:
        """Get status of a running or completed execution."""
        if run_id in self._active_runs:
            run_data = self._active_runs[run_id].copy()
            
            # Convert datetime objects to ISO strings for JSON serialization
            for key in ['started_at', 'ended_at']:
                if key in run_data and run_data[key]:
                    if isinstance(run_data[key], datetime):
                        run_data[key] = run_data[key].isoformat()
            
            # Convert step datetimes
            for step in run_data.get('steps', []):
                for key in ['started_at', 'ended_at']:
                    if key in step and step[key]:
                        if isinstance(step[key], datetime):
                            step[key] = step[key].isoformat()
            
            return {
                "run_id": run_id,
                "status": run_data["status"],
                "progress": {
                    "current": run_data["current_step"],
                    "total": run_data["total_steps"]
                },
                "artifacts": run_data.get("artifacts", [])
            }
        
        return None

    async def cancel_run(self, run_id: str) -> bool:
        """Cancel an active run."""
        if run_id in self._active_runs:
            run_data = self._active_runs[run_id]
            run_data.update({
                "status": "cancelled",
                "ended_at": datetime.utcnow()
            })
            
            # Log cancellation to OpenSearch
            await self.opensearch_logger.log_run(
                run_id=run_id,
                tenant_id=run_data["tenant_id"],
                status="cancelled",
                plan_id=run_data.get("plan_id", ""),
                steps_count=run_data["current_step"],
                started_at=run_data["started_at"],
                ended_at=run_data["ended_at"],
                artifacts=run_data.get("artifacts", []),
                summary={
                    "total_findings": 0,
                    "severity": "info",
                    "duration_ms": int((run_data["ended_at"] - run_data["started_at"]).total_seconds() * 1000),
                    "cancelled": True,
                    "features": [],
                    "depth": "unknown",
                    "simulate": run_data["simulate"]
                }
            )
            
            return True
        
        return False

    def get_active_runs(self) -> List[str]:
        """Get list of active run IDs."""
        return [
            run_id for run_id, data in self._active_runs.items()
            if data.get("status") == "running"
        ]

    async def health_check(self) -> Dict[str, Any]:
        """Check health of the executor and its dependencies."""
        try:
            # Check CrewAI registry
            agents = self.crew_registry.get_available_agents()
            tools = self.crew_registry.get_available_tools()
            
            # Check OpenSearch logger
            logger_health = await self.opensearch_logger.health_check()
            
            return {
                "status": "healthy",
                "active_runs": len(self.get_active_runs()),
                "available_agents": len(agents),
                "available_tools": sum(len(tool_list) for tool_list in tools.values()),
                "opensearch_healthy": logger_health,
                "crew_registry_healthy": len(agents) > 0
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }
