"""Enhanced OpenSearch logging for dynamic task execution and agent activity tracking."""

import json
import uuid
import statistics
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Union
from dataclasses import dataclass, asdict, field
from enum import Enum

try:
    import structlog
    logger = structlog.get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)

from .config import OpenSearchConfig, Settings
from .opensearch_client import OpenSearchClient, create_opensearch_client


class TaskStatus(str, Enum):
    """Task execution status enumeration."""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    ERROR = "error"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"
    RETRYING = "retrying"


class AgentType(str, Enum):
    """Agent type classification."""
    RECONNAISSANCE = "reconnaissance"
    WEB_SECURITY = "web_security"
    VULNERABILITY = "vulnerability"
    EXPLOITATION = "exploitation"
    CREDENTIAL = "credential"
    LATERAL_MOVEMENT = "lateral_movement"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    POST_EXPLOITATION = "post_exploitation"


@dataclass
class TaskExecutionMetrics:
    """Metrics for task execution performance."""
    execution_time_ms: int
    memory_usage_mb: Optional[float] = None
    cpu_usage_percent: Optional[float] = None
    network_requests: int = 0
    file_operations: int = 0
    command_executions: int = 0
    api_calls: int = 0


@dataclass
class AgentContext:
    """Enhanced agent context information."""
    agent_id: str
    agent_name: str
    agent_type: AgentType
    agent_version: str
    capabilities: List[str]
    assigned_tools: List[str]
    model_provider: Optional[str] = None
    model_name: Optional[str] = None


@dataclass
class TaskContext:
    """Enhanced task context information."""
    task_id: str
    task_name: str
    task_type: str
    parent_run_id: str
    workflow_step: int
    priority: int = 5  # 1-10 scale
    dependencies: List[str] = field(default_factory=list)
    retry_count: int = 0
    max_retries: int = 3
    timeout_seconds: int = 300


@dataclass
class SecurityContext:
    """Security and compliance context."""
    authorization_level: str
    approved_targets: List[str]
    restricted_actions: List[str]
    compliance_tags: List[str]
    risk_level: str = "medium"  # low, medium, high, critical


@dataclass
class ExecutionResult:
    """Comprehensive execution result."""
    status: TaskStatus
    output_data: Dict[str, Any]
    findings: List[Dict[str, Any]]
    artifacts_created: List[str]
    errors: List[Dict[str, Any]]
    warnings: List[Dict[str, Any]]
    recommendations: List[str]
    confidence_score: Optional[float] = None


class EnhancedOpenSearchLogger:
    """Enhanced OpenSearch logger for comprehensive agent and task tracking."""

    def __init__(self, config: OpenSearchConfig):
        """Initialize enhanced OpenSearch logger."""
        self.config = config
        self.client = create_opensearch_client(config)
        
        # Enhanced index names
        self.index_agent_activities = f"{config.index_actions}-enhanced"
        self.index_task_executions = f"{config.index_runs}-tasks"
        self.index_agent_performance = "cybrty-agent-performance"
        self.index_security_events = "cybrty-security-events"
        self.index_workflow_analytics = "cybrty-workflow-analytics"

    async def ensure_enhanced_indices(self) -> None:
        """Ensure all enhanced indices exist with proper mappings."""
        await self.client.ensure_indices()
        
        # Create enhanced index mappings
        enhanced_mappings = await self._get_enhanced_index_mappings()
        
        for index_name, mapping in enhanced_mappings.items():
            try:
                await self.client._create_index_if_not_exists(index_name, mapping)
                logger.info(f"Enhanced index ensured: {index_name}")
            except Exception as e:
                logger.error(f"Failed to create enhanced index {index_name}: {str(e)}")

    async def _get_enhanced_index_mappings(self) -> Dict[str, Dict[str, Any]]:
        """Get enhanced index mappings for comprehensive logging."""
        return {
            self.index_agent_activities: {
                "mappings": {
                    "properties": {
                        # Basic identifiers
                        "activity_id": {"type": "keyword"},
                        "run_id": {"type": "keyword"},
                        "task_id": {"type": "keyword"},
                        "tenant_id": {"type": "keyword"},
                        
                        # Agent information
                        "agent_id": {"type": "keyword"},
                        "agent_name": {"type": "keyword"},
                        "agent_type": {"type": "keyword"},
                        "agent_version": {"type": "keyword"},
                        "capabilities": {"type": "keyword"},
                        "assigned_tools": {"type": "keyword"},
                        "model_provider": {"type": "keyword"},
                        "model_name": {"type": "keyword"},
                        
                        # Task execution
                        "task_name": {"type": "keyword"},
                        "task_type": {"type": "keyword"},
                        "workflow_step": {"type": "integer"},
                        "priority": {"type": "integer"},
                        "status": {"type": "keyword"},
                        "retry_count": {"type": "integer"},
                        
                        # Performance metrics
                        "execution_time_ms": {"type": "long"},
                        "memory_usage_mb": {"type": "float"},
                        "cpu_usage_percent": {"type": "float"},
                        "network_requests": {"type": "integer"},
                        "file_operations": {"type": "integer"},
                        "command_executions": {"type": "integer"},
                        "api_calls": {"type": "integer"},
                        
                        # Results and findings
                        "findings_count": {"type": "integer"},
                        "artifacts_count": {"type": "integer"},
                        "errors_count": {"type": "integer"},
                        "warnings_count": {"type": "integer"},
                        "confidence_score": {"type": "float"},
                        
                        # Security context
                        "authorization_level": {"type": "keyword"},
                        "risk_level": {"type": "keyword"},
                        "compliance_tags": {"type": "keyword"},
                        
                        # Detailed data (stored but not analyzed)
                        "input_params": {"type": "object", "enabled": False},
                        "output_data": {"type": "object", "enabled": False},
                        "findings": {"type": "object", "enabled": False},
                        "artifacts": {"type": "object", "enabled": False},
                        "errors": {"type": "object", "enabled": False},
                        
                        # Timestamps
                        "started_at": {"type": "date"},
                        "ended_at": {"type": "date"},
                        "created_at": {"type": "date"},
                        "@timestamp": {"type": "date"}
                    }
                }
            },
            
            self.index_task_executions: {
                "mappings": {
                    "properties": {
                        # Task identification
                        "task_execution_id": {"type": "keyword"},
                        "task_id": {"type": "keyword"},
                        "run_id": {"type": "keyword"},
                        "tenant_id": {"type": "keyword"},
                        
                        # Task definition
                        "task_name": {"type": "text", "fields": {"keyword": {"type": "keyword"}}},
                        "task_description": {"type": "text"},
                        "task_type": {"type": "keyword"},
                        "expected_output": {"type": "text"},
                        
                        # Execution context
                        "workflow_step": {"type": "integer"},
                        "total_steps": {"type": "integer"},
                        "execution_order": {"type": "integer"},
                        "parallel_execution": {"type": "boolean"},
                        
                        # Status tracking
                        "status": {"type": "keyword"},
                        "progress_percentage": {"type": "float"},
                        "current_sub_task": {"type": "text"},
                        
                        # Agent assignment
                        "assigned_agent_id": {"type": "keyword"},
                        "agent_capabilities_used": {"type": "keyword"},
                        "tools_utilized": {"type": "keyword"},
                        
                        # Performance data
                        "execution_metrics": {"type": "object", "enabled": False},
                        "resource_usage": {"type": "object", "enabled": False},
                        
                        # Results summary
                        "execution_summary": {"type": "object", "enabled": False},
                        "quality_score": {"type": "float"},
                        
                        # Timestamps
                        "scheduled_at": {"type": "date"},
                        "started_at": {"type": "date"},
                        "ended_at": {"type": "date"},
                        "@timestamp": {"type": "date"}
                    }
                }
            },
            
            self.index_agent_performance: {
                "mappings": {
                    "properties": {
                        "performance_id": {"type": "keyword"},
                        "agent_id": {"type": "keyword"},
                        "agent_name": {"type": "keyword"},
                        "measurement_period": {"type": "keyword"},
                        "tasks_completed": {"type": "integer"},
                        "tasks_failed": {"type": "integer"},
                        "average_execution_time": {"type": "float"},
                        "success_rate": {"type": "float"},
                        "average_confidence": {"type": "float"},
                        "resource_efficiency": {"type": "float"},
                        "findings_per_task": {"type": "float"},
                        "error_patterns": {"type": "object", "enabled": False},
                        "performance_trends": {"type": "object", "enabled": False},
                        "measured_at": {"type": "date"}
                    }
                }
            },
            
            self.index_security_events: {
                "mappings": {
                    "properties": {
                        "event_id": {"type": "keyword"},
                        "event_type": {"type": "keyword"},
                        "severity": {"type": "keyword"},
                        "run_id": {"type": "keyword"},
                        "agent_id": {"type": "keyword"},
                        "event_description": {"type": "text"},
                        "target_affected": {"type": "keyword"},
                        "action_taken": {"type": "text"},
                        "compliance_violation": {"type": "boolean"},
                        "auto_resolved": {"type": "boolean"},
                        "event_data": {"type": "object", "enabled": False},
                        "occurred_at": {"type": "date"}
                    }
                }
            }
        }

    async def log_agent_activity(
        self,
        agent_context: AgentContext,
        task_context: TaskContext,
        security_context: SecurityContext,
        execution_result: ExecutionResult,
        metrics: TaskExecutionMetrics,
        input_params: Dict[str, Any],
        started_at: datetime,
        ended_at: datetime
    ) -> bool:
        """Log comprehensive agent activity."""
        
        activity_id = str(uuid.uuid4())
        
        doc = {
            # Basic identifiers
            "activity_id": activity_id,
            "run_id": task_context.parent_run_id,
            "task_id": task_context.task_id,
            "tenant_id": security_context.authorization_level.split("-")[0] if "-" in security_context.authorization_level else "default",
            
            # Agent information
            "agent_id": agent_context.agent_id,
            "agent_name": agent_context.agent_name,
            "agent_type": agent_context.agent_type.value,
            "agent_version": agent_context.agent_version,
            "capabilities": agent_context.capabilities,
            "assigned_tools": agent_context.assigned_tools,
            "model_provider": agent_context.model_provider,
            "model_name": agent_context.model_name,
            
            # Task execution
            "task_name": task_context.task_name,
            "task_type": task_context.task_type,
            "workflow_step": task_context.workflow_step,
            "priority": task_context.priority,
            "status": execution_result.status.value,
            "retry_count": task_context.retry_count,
            
            # Performance metrics
            "execution_time_ms": metrics.execution_time_ms,
            "memory_usage_mb": metrics.memory_usage_mb,
            "cpu_usage_percent": metrics.cpu_usage_percent,
            "network_requests": metrics.network_requests,
            "file_operations": metrics.file_operations,
            "command_executions": metrics.command_executions,
            "api_calls": metrics.api_calls,
            
            # Results and findings
            "findings_count": len(execution_result.findings),
            "artifacts_count": len(execution_result.artifacts_created),
            "errors_count": len(execution_result.errors),
            "warnings_count": len(execution_result.warnings),
            "confidence_score": execution_result.confidence_score,
            
            # Security context
            "authorization_level": security_context.authorization_level,
            "risk_level": security_context.risk_level,
            "compliance_tags": security_context.compliance_tags,
            
            # Detailed data (stored but not analyzed)
            "input_params": input_params,
            "output_data": execution_result.output_data,
            "findings": execution_result.findings,
            "artifacts": execution_result.artifacts_created,
            "errors": execution_result.errors,
            
            # Timestamps
            "started_at": started_at.isoformat(),
            "ended_at": ended_at.isoformat(),
            "created_at": datetime.utcnow().isoformat(),
            "@timestamp": datetime.utcnow().isoformat()
        }
        
        success = await self.client.index_document(self.index_agent_activities, doc, doc_id=activity_id)
        
        if success:
            logger.info(
                f"Agent activity logged: {activity_id}, agent: {agent_context.agent_name}, "
                f"task: {task_context.task_name}, status: {execution_result.status.value}"
            )
        
        return success

    async def log_task_execution(
        self,
        task_context: TaskContext,
        agent_context: AgentContext,
        execution_result: ExecutionResult,
        progress_data: Dict[str, Any],
        scheduled_at: datetime,
        started_at: datetime,
        ended_at: Optional[datetime] = None
    ) -> bool:
        """Log detailed task execution information."""
        
        execution_id = str(uuid.uuid4())
        
        doc = {
            # Task identification
            "task_execution_id": execution_id,
            "task_id": task_context.task_id,
            "run_id": task_context.parent_run_id,
            "tenant_id": "default",  # Extract from context if needed
            
            # Task definition
            "task_name": task_context.task_name,
            "task_description": progress_data.get("description", ""),
            "task_type": task_context.task_type,
            "expected_output": progress_data.get("expected_output", ""),
            
            # Execution context
            "workflow_step": task_context.workflow_step,
            "total_steps": progress_data.get("total_steps", 1),
            "execution_order": task_context.workflow_step,
            "parallel_execution": progress_data.get("parallel", False),
            
            # Status tracking
            "status": execution_result.status.value,
            "progress_percentage": progress_data.get("progress", 0.0),
            "current_sub_task": progress_data.get("current_sub_task", ""),
            
            # Agent assignment
            "assigned_agent_id": agent_context.agent_id,
            "agent_capabilities_used": agent_context.capabilities,
            "tools_utilized": agent_context.assigned_tools,
            
            # Performance data
            "execution_metrics": asdict(progress_data.get("metrics", {})),
            "resource_usage": progress_data.get("resource_usage", {}),
            
            # Results summary
            "execution_summary": {
                "findings_count": len(execution_result.findings),
                "artifacts_count": len(execution_result.artifacts_created),
                "success": execution_result.status == TaskStatus.SUCCESS,
                "confidence": execution_result.confidence_score
            },
            "quality_score": execution_result.confidence_score or 0.0,
            
            # Timestamps
            "scheduled_at": scheduled_at.isoformat(),
            "started_at": started_at.isoformat(),
            "ended_at": ended_at.isoformat() if ended_at else None,
            "@timestamp": datetime.utcnow().isoformat()
        }
        
        return await self.client.index_document(self.index_task_executions, doc, doc_id=execution_id)

    async def log_security_event(
        self,
        event_type: str,
        severity: str,
        description: str,
        run_id: str,
        agent_id: str,
        target_affected: Optional[str] = None,
        action_taken: Optional[str] = None,
        compliance_violation: bool = False,
        event_data: Optional[Dict[str, Any]] = None
    ) -> bool:
        """Log security-related events during execution."""
        
        event_id = str(uuid.uuid4())
        
        doc = {
            "event_id": event_id,
            "event_type": event_type,
            "severity": severity,
            "run_id": run_id,
            "agent_id": agent_id,
            "event_description": description,
            "target_affected": target_affected,
            "action_taken": action_taken,
            "compliance_violation": compliance_violation,
            "auto_resolved": False,  # Can be updated later
            "event_data": event_data or {},
            "occurred_at": datetime.utcnow().isoformat()
        }
        
        return await self.client.index_document(self.index_security_events, doc, doc_id=event_id)

    async def update_agent_performance_metrics(
        self,
        agent_id: str,
        agent_name: str,
        period: str = "hourly"
    ) -> bool:
        """Calculate and store agent performance metrics."""
        
        # Query recent activities for the agent
        query = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"agent_id.keyword": agent_id}},
                        {"range": {"@timestamp": {"gte": "now-1h"}}}
                    ]
                }
            },
            "size": 1000
        }
        
        activities = await self.client.search_documents(self.index_agent_activities, query)
        
        if not activities:
            return True  # No recent activities
        
        # Calculate performance metrics
        total_tasks = len(activities)
        successful_tasks = len([a for a in activities if a["status"] == "success"])
        failed_tasks = len([a for a in activities if a["status"] == "error"])
        
        avg_execution_time = sum(a["execution_time_ms"] for a in activities) / total_tasks
        success_rate = successful_tasks / total_tasks if total_tasks > 0 else 0.0
        avg_confidence = sum(a.get("confidence_score", 0) or 0 for a in activities) / total_tasks
        avg_findings = sum(a["findings_count"] for a in activities) / total_tasks
        
        performance_doc = {
            "performance_id": str(uuid.uuid4()),
            "agent_id": agent_id,
            "agent_name": agent_name,
            "measurement_period": period,
            "tasks_completed": successful_tasks,
            "tasks_failed": failed_tasks,
            "average_execution_time": avg_execution_time,
            "success_rate": success_rate,
            "average_confidence": avg_confidence,
            "resource_efficiency": 1.0 - (avg_execution_time / 300000),  # Normalized to 5 minutes
            "findings_per_task": avg_findings,
            "error_patterns": self._analyze_error_patterns(activities),
            "performance_trends": self._calculate_performance_trends(activities),
            "measured_at": datetime.utcnow().isoformat()
        }
        
        return await self.client.index_document(self.index_agent_performance, performance_doc)

    def _analyze_error_patterns(self, activities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze error patterns from agent activities."""
        error_activities = [a for a in activities if a["status"] == "error"]
        
        if not error_activities:
            return {}
        
        error_types = {}
        for activity in error_activities:
            for error in activity.get("errors", []):
                error_type = error.get("type", "unknown")
                error_types[error_type] = error_types.get(error_type, 0) + 1
        
        return {
            "total_errors": len(error_activities),
            "error_types": error_types,
            "error_rate": len(error_activities) / len(activities),
            "most_common_error": max(error_types.items(), key=lambda x: x[1])[0] if error_types else None
        }

    def _calculate_performance_trends(self, activities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate performance trends over time."""
        if len(activities) < 2:
            return {}
        
        # Sort by timestamp
        sorted_activities = sorted(activities, key=lambda x: x["started_at"])
        
        # Calculate trends
        first_half = sorted_activities[:len(sorted_activities)//2]
        second_half = sorted_activities[len(sorted_activities)//2:]
        
        first_avg_time = sum(a["execution_time_ms"] for a in first_half) / len(first_half)
        second_avg_time = sum(a["execution_time_ms"] for a in second_half) / len(second_half)
        
        execution_times = [a["execution_time_ms"] for a in activities]
        if len(execution_times) > 1:
            mean_time = statistics.mean(execution_times)
            stdev_time = statistics.stdev(execution_times)
            consistency_score = 1.0 - (stdev_time / mean_time) if mean_time > 0 else 1.0
        else:
            consistency_score = 1.0
        
        return {
            "execution_time_trend": "improving" if second_avg_time < first_avg_time else "degrading",
            "time_change_percent": ((second_avg_time - first_avg_time) / first_avg_time) * 100,
            "consistency_score": consistency_score
        }

    async def get_agent_dashboard_data(self, agent_id: str, time_range: str = "24h") -> Dict[str, Any]:
        """Get comprehensive dashboard data for an agent."""
        
        time_query = f"now-{time_range}"
        
        # Query agent activities
        activities_query = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"agent_id.keyword": agent_id}},
                        {"range": {"@timestamp": {"gte": time_query}}}
                    ]
                }
            },
            "size": 1000,
            "sort": [{"@timestamp": {"order": "desc"}}]
        }
        
        activities = await self.client.search_documents(self.index_agent_activities, activities_query)
        
        # Query performance metrics
        performance_query = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"agent_id.keyword": agent_id}},
                        {"range": {"measured_at": {"gte": time_query}}}
                    ]
                }
            },
            "size": 100,
            "sort": [{"measured_at": {"order": "desc"}}]
        }
        
        performance_data = await self.client.search_documents(self.index_agent_performance, performance_query)
        
        return {
            "agent_id": agent_id,
            "time_range": time_range,
            "total_activities": len(activities),
            "recent_performance": performance_data[0] if performance_data else None,
            "activity_summary": self._summarize_activities(activities),
            "performance_history": performance_data[:10],  # Last 10 measurements
            "status_distribution": self._get_status_distribution(activities),
            "findings_summary": self._summarize_findings(activities),
            "generated_at": datetime.utcnow().isoformat()
        }

    def _summarize_activities(self, activities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Summarize agent activities."""
        if not activities:
            return {}
        
        return {
            "total_tasks": len(activities),
            "successful_tasks": len([a for a in activities if a["status"] == "success"]),
            "failed_tasks": len([a for a in activities if a["status"] == "error"]),
            "average_duration": sum(a["execution_time_ms"] for a in activities) / len(activities),
            "total_findings": sum(a["findings_count"] for a in activities),
            "total_artifacts": sum(a["artifacts_count"] for a in activities)
        }

    def _get_status_distribution(self, activities: List[Dict[str, Any]]) -> Dict[str, int]:
        """Get distribution of task statuses."""
        distribution = {}
        for activity in activities:
            status = activity["status"]
            distribution[status] = distribution.get(status, 0) + 1
        return distribution

    def _summarize_findings(self, activities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Summarize findings across activities."""
        all_findings = []
        for activity in activities:
            all_findings.extend(activity.get("findings", []))
        
        if not all_findings:
            return {}
        
        severity_counts = {}
        for finding in all_findings:
            severity = finding.get("severity", "unknown")
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        return {
            "total_findings": len(all_findings),
            "severity_distribution": severity_counts,
            "unique_finding_types": len(set(f.get("type", "unknown") for f in all_findings))
        }

    async def health_check(self) -> bool:
        """Check health of the enhanced logger."""
        return await self.client.health_check()

    async def close(self) -> None:
        """Close the enhanced logger."""
        await self.client.close()


# Dependency injection helpers
def get_enhanced_opensearch_logger(settings: Settings) -> EnhancedOpenSearchLogger:
    """Get enhanced OpenSearch logger instance."""
    return EnhancedOpenSearchLogger(settings.opensearch)


async def setup_enhanced_opensearch_logger(settings: Settings) -> EnhancedOpenSearchLogger:
    """Setup enhanced OpenSearch logger with indices."""
    logger_instance = get_enhanced_opensearch_logger(settings)
    await logger_instance.ensure_enhanced_indices()
    return logger_instance
