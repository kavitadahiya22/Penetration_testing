"""Enhanced CrewAI executor with comprehensive logging and monitoring."""

import asyncio
import json
import uuid
import statistics
from datetime import datetime
from typing import Any, Dict, List, Optional
from pathlib import Path

try:
    from crewai import Crew, Task
    CREWAI_AVAILABLE = True
    CrewType = Crew
    TaskType = Task
except ImportError:
    CREWAI_AVAILABLE = False
    CrewType = Any
    TaskType = Any

from .config import Settings
from .enhanced_logger import (
    EnhancedOpenSearchLogger, 
    AgentContext, 
    TaskContext, 
    SecurityContext, 
    ExecutionResult, 
    TaskExecutionMetrics,
    TaskStatus,
    AgentType
)
from .crew.registry import CrewRegistry
from .crew_executor import CrewAIPentestExecutor

try:
    import structlog
    logger = structlog.get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


class EnhancedCrewExecutor(CrewAIPentestExecutor):
    """Enhanced CrewAI executor with comprehensive logging and monitoring."""

    def __init__(
        self, 
        settings: Settings, 
        enhanced_logger: EnhancedOpenSearchLogger
    ):
        """Initialize enhanced crew executor."""
        # Initialize base executor with a dummy logger for now
        from .logger import get_opensearch_logger
        base_logger = get_opensearch_logger(settings)
        super().__init__(settings, base_logger)
        
        self.enhanced_logger = enhanced_logger
        self.agent_contexts: Dict[str, AgentContext] = {}
        self.task_metrics: Dict[str, TaskExecutionMetrics] = {}
        
        # Initialize agent contexts
        self._initialize_agent_contexts()

    def _initialize_agent_contexts(self) -> None:
        """Initialize agent contexts for tracking."""
        agent_configs = {
            "recon": {
                "type": AgentType.RECONNAISSANCE,
                "capabilities": ["network_scanning", "host_discovery", "service_enumeration"],
                "tools": ["nmap", "amass"]
            },
            "web": {
                "type": AgentType.WEB_SECURITY,
                "capabilities": ["web_scanning", "vulnerability_detection", "sql_injection_testing"],
                "tools": ["zap", "nikto", "sqlmap"]
            },
            "exploit": {
                "type": AgentType.EXPLOITATION,
                "capabilities": ["vulnerability_validation", "exploit_development", "payload_delivery"],
                "tools": ["metasploit"]
            },
            "creds": {
                "type": AgentType.CREDENTIAL,
                "capabilities": ["credential_testing", "brute_force", "authentication_bypass"],
                "tools": ["hydra", "crackmapexec"]
            },
            "lateral": {
                "type": AgentType.LATERAL_MOVEMENT,
                "capabilities": ["domain_analysis", "privilege_mapping", "movement_planning"],
                "tools": ["bloodhound", "crackmapexec"]
            },
            "priv-esc": {
                "type": AgentType.PRIVILEGE_ESCALATION,
                "capabilities": ["privilege_analysis", "escalation_path_discovery", "misconfiguration_detection"],
                "tools": ["bloodhound"]
            }
        }
        
        for agent_name, config in agent_configs.items():
            self.agent_contexts[agent_name] = AgentContext(
                agent_id=f"{agent_name}_{uuid.uuid4().hex[:8]}",
                agent_name=agent_name,
                agent_type=config["type"],
                agent_version="1.0.0",
                capabilities=config["capabilities"],
                assigned_tools=config["tools"],
                model_provider=self.settings.model.provider,
                model_name=self.settings.model.model_name
            )

    async def execute_plan(
        self,
        plan: Dict[str, Any],
        tenant_id: str,
        simulate: bool = True
    ) -> str:
        """Execute a pentesting plan with enhanced logging."""
        run_id = str(uuid.uuid4())
        start_time = datetime.utcnow()
        
        try:
            # Log run start
            logger.info(f"Starting enhanced CrewAI execution: {run_id}")
            
            # Initialize run tracking
            run_data = {
                "run_id": run_id,
                "tenant_id": tenant_id,
                "plan_id": plan.get("plan_id"),
                "status": "running",
                "started_at": start_time,
                "steps": [],
                "current_step": 0,
                "total_steps": len(plan.get("steps", [])),
                "simulate": simulate,
                "artifacts": []
            }
            
            self._active_runs[run_id] = run_data
            
            # Create security context
            security_context = SecurityContext(
                authorization_level=f"{tenant_id}-standard",
                approved_targets=self._extract_targets_from_plan(plan),
                restricted_actions=["exploitation"] if simulate else [],
                compliance_tags=["pentest", "authorized"],
                risk_level="medium"
            )
            
            # Create CrewAI crew from plan
            crew = self.crew_registry.create_crew(plan.get("steps", []))
            
            # Execute crew workflow asynchronously with enhanced logging
            asyncio.create_task(
                self._execute_enhanced_crew_workflow(
                    crew, plan, run_id, tenant_id, security_context
                )
            )
            
            return run_id
            
        except Exception as e:
            logger.error(f"Enhanced CrewAI execution initialization failed: {str(e)}")
            raise

    async def _execute_enhanced_crew_workflow(
        self,
        crew: Any,
        plan: Dict[str, Any],
        run_id: str,
        tenant_id: str,
        security_context: SecurityContext
    ) -> None:
        """Execute CrewAI workflow with enhanced logging and monitoring."""
        started_at = datetime.utcnow()
        
        try:
            logger.info(f"Starting enhanced crew workflow: {run_id}")
            
            # Log security event for run start
            await self.enhanced_logger.log_security_event(
                event_type="workflow_started",
                severity="info",
                description=f"Enhanced pentesting workflow started with {len(crew.agents)} agents",
                run_id=run_id,
                agent_id="system",
                event_data={"plan_id": plan.get("plan_id"), "simulate": self._active_runs[run_id]["simulate"]}
            )
            
            # Execute crew
            crew_result = crew.kickoff()
            
            # Process individual tasks with enhanced logging
            step_results = []
            total_findings = 0
            max_severity = "info"
            all_artifacts = []
            
            for i, task in enumerate(crew.tasks):
                step_start = datetime.utcnow()
                
                try:
                    # Get agent context
                    agent_name = self._extract_agent_name_from_task(task)
                    agent_context = self.agent_contexts.get(agent_name)
                    
                    if not agent_context:
                        logger.warning(f"No agent context found for {agent_name}")
                        continue
                    
                    # Create task context
                    task_context = TaskContext(
                        task_id=f"task_{run_id}_{i+1}",
                        task_name=f"{agent_name}_task_{i+1}",
                        task_type=agent_name,
                        parent_run_id=run_id,
                        workflow_step=i + 1,
                        priority=5,
                        retry_count=0
                    )
                    
                    # Log task start
                    await self.enhanced_logger.log_task_execution(
                        task_context=task_context,
                        agent_context=agent_context,
                        execution_result=ExecutionResult(
                            status=TaskStatus.RUNNING,
                            output_data={},
                            findings=[],
                            artifacts_created=[],
                            errors=[],
                            warnings=[],
                            recommendations=[]
                        ),
                        progress_data={
                            "description": getattr(task, 'description', ''),
                            "expected_output": getattr(task, 'expected_output', ''),
                            "total_steps": len(crew.tasks),
                            "progress": 0.0
                        },
                        scheduled_at=started_at,
                        started_at=step_start
                    )
                    
                    # Simulate task execution with monitoring
                    task_result = await self._execute_monitored_task(
                        task, agent_context, task_context, security_context, run_id
                    )
                    
                    step_end = datetime.utcnow()
                    duration_ms = int((step_end - step_start).total_seconds() * 1000)
                    
                    # Create execution metrics
                    metrics = TaskExecutionMetrics(
                        execution_time_ms=duration_ms,
                        memory_usage_mb=self._estimate_memory_usage(),
                        cpu_usage_percent=self._estimate_cpu_usage(),
                        network_requests=self._count_network_requests(task_result),
                        file_operations=self._count_file_operations(task_result),
                        command_executions=1,  # Each task executes at least one command
                        api_calls=0
                    )
                    
                    # Create execution result
                    findings = self._extract_findings_from_result(task_result)
                    artifacts = self._extract_artifacts_from_result(task_result, run_id, task_context.task_id)
                    
                    execution_result = ExecutionResult(
                        status=TaskStatus.SUCCESS,
                        output_data={"result": str(task_result)},
                        findings=findings,
                        artifacts_created=list(artifacts.values()),
                        errors=[],
                        warnings=[],
                        recommendations=self._generate_recommendations(findings),
                        confidence_score=self._calculate_confidence_score(findings)
                    )
                    
                    # Log comprehensive agent activity
                    await self.enhanced_logger.log_agent_activity(
                        agent_context=agent_context,
                        task_context=task_context,
                        security_context=security_context,
                        execution_result=execution_result,
                        metrics=metrics,
                        input_params=self._extract_task_params(task),
                        started_at=step_start,
                        ended_at=step_end
                    )
                    
                    # Log task completion
                    await self.enhanced_logger.log_task_execution(
                        task_context=task_context,
                        agent_context=agent_context,
                        execution_result=execution_result,
                        progress_data={
                            "description": getattr(task, 'description', ''),
                            "expected_output": getattr(task, 'expected_output', ''),
                            "total_steps": len(crew.tasks),
                            "progress": 100.0,
                            "metrics": metrics
                        },
                        scheduled_at=started_at,
                        started_at=step_start,
                        ended_at=step_end
                    )
                    
                    # Update run tracking
                    step_data = {
                        "step_id": task_context.task_id,
                        "agent": agent_name,
                        "tool": self._extract_tool_from_task(task),
                        "status": "success",
                        "started_at": step_start,
                        "ended_at": step_end,
                        "duration_ms": duration_ms,
                        "findings_count": len(findings),
                        "artifacts": artifacts,
                        "params": self._extract_task_params(task),
                        "summary": {
                            "output": str(task_result),
                            "findings": len(findings),
                            "confidence": execution_result.confidence_score
                        }
                    }
                    
                    step_results.append(step_data)
                    total_findings += len(findings)
                    all_artifacts.extend(artifacts.values())
                    
                    # Update active run tracking
                    if run_id in self._active_runs:
                        self._active_runs[run_id]["steps"].append(step_data)
                        self._active_runs[run_id]["current_step"] = i + 1
                    
                except Exception as step_error:
                    logger.error(f"Enhanced step execution failed: {str(step_error)}")
                    
                    step_end = datetime.utcnow()
                    duration_ms = int((step_end - step_start).total_seconds() * 1000)
                    
                    # Log error activity
                    if agent_context:
                        error_result = ExecutionResult(
                            status=TaskStatus.ERROR,
                            output_data={},
                            findings=[],
                            artifacts_created=[],
                            errors=[{"type": "execution_error", "message": str(step_error)}],
                            warnings=[],
                            recommendations=[]
                        )
                        
                        error_metrics = TaskExecutionMetrics(
                            execution_time_ms=duration_ms,
                            command_executions=0
                        )
                        
                        await self.enhanced_logger.log_agent_activity(
                            agent_context=agent_context,
                            task_context=task_context,
                            security_context=security_context,
                            execution_result=error_result,
                            metrics=error_metrics,
                            input_params=self._extract_task_params(task),
                            started_at=step_start,
                            ended_at=step_end
                        )
                    
                    # Log security event for error
                    await self.enhanced_logger.log_security_event(
                        event_type="task_execution_error",
                        severity="warning",
                        description=f"Task execution failed: {str(step_error)}",
                        run_id=run_id,
                        agent_id=agent_context.agent_id if agent_context else "unknown",
                        event_data={"error": str(step_error), "step": i}
                    )
            
            # Complete run logging
            ended_at = datetime.utcnow()
            duration_ms = int((ended_at - started_at).total_seconds() * 1000)
            
            self._active_runs[run_id]["status"] = "completed"
            self._active_runs[run_id]["ended_at"] = ended_at
            self._active_runs[run_id]["artifacts"] = all_artifacts
            
            # Update agent performance metrics
            for agent_name in self.agent_contexts:
                await self.enhanced_logger.update_agent_performance_metrics(
                    agent_id=self.agent_contexts[agent_name].agent_id,
                    agent_name=agent_name
                )
            
            # Log security event for completion
            await self.enhanced_logger.log_security_event(
                event_type="workflow_completed",
                severity="info",
                description=f"Enhanced workflow completed successfully with {total_findings} findings",
                run_id=run_id,
                agent_id="system",
                event_data={
                    "total_findings": total_findings,
                    "duration_ms": duration_ms,
                    "steps_completed": len(step_results)
                }
            )
            
            logger.info(f"Enhanced crew execution completed: {run_id}")
            
        except Exception as e:
            logger.error(f"Enhanced crew workflow failed: {str(e)}")
            
            # Log security event for failure
            await self.enhanced_logger.log_security_event(
                event_type="workflow_failed",
                severity="error",
                description=f"Enhanced workflow failed: {str(e)}",
                run_id=run_id,
                agent_id="system",
                event_data={"error": str(e)}
            )
            
            ended_at = datetime.utcnow()
            self._active_runs[run_id]["status"] = "error"
            self._active_runs[run_id]["ended_at"] = ended_at
            self._active_runs[run_id]["error"] = str(e)

    async def _execute_monitored_task(
        self,
        task: Any,
        agent_context: AgentContext,
        task_context: TaskContext,
        security_context: SecurityContext,
        run_id: str
    ) -> str:
        """Execute a task with comprehensive monitoring."""
        try:
            # Monitor task execution
            start_time = datetime.utcnow()
            
            # Simulate task execution (in real implementation, this would call the actual task)
            result = f"Simulated execution of {task_context.task_name} by {agent_context.agent_name}"
            
            # Check for security violations
            if "exploit" in task_context.task_name.lower() and "exploitation" in security_context.restricted_actions:
                await self.enhanced_logger.log_security_event(
                    event_type="security_violation",
                    severity="warning",
                    description=f"Attempted restricted action: exploitation",
                    run_id=run_id,
                    agent_id=agent_context.agent_id,
                    compliance_violation=True,
                    event_data={"task": task_context.task_name, "restriction": "exploitation"}
                )
                result += " (SIMULATED - exploitation restricted)"
            
            return result
            
        except Exception as e:
            logger.error(f"Monitored task execution failed: {str(e)}")
            raise

    def _extract_agent_name_from_task(self, task: Any) -> str:
        """Extract agent name from CrewAI task."""
        if hasattr(task, 'agent') and hasattr(task.agent, 'role'):
            role = task.agent.role.lower()
            if "reconnaissance" in role:
                return "recon"
            elif "web" in role:
                return "web"
            elif "exploit" in role:
                return "exploit"
            elif "credential" in role:
                return "creds"
            elif "lateral" in role:
                return "lateral"
            elif "privilege" in role:
                return "priv-esc"
        return "unknown"

    def _extract_targets_from_plan(self, plan: Dict[str, Any]) -> List[str]:
        """Extract targets from execution plan."""
        targets = []
        for step in plan.get("steps", []):
            if "targets" in step.get("params", {}):
                targets.extend(step["params"]["targets"])
            if "target" in step.get("params", {}):
                targets.append(step["params"]["target"])
        return list(set(targets))

    def _extract_task_params(self, task: Any) -> Dict[str, Any]:
        """Extract parameters from CrewAI task."""
        return {
            "description": getattr(task, 'description', ''),
            "expected_output": getattr(task, 'expected_output', ''),
            "agent_role": getattr(task.agent, 'role', 'unknown') if hasattr(task, 'agent') else 'unknown'
        }

    def _extract_findings_from_result(self, result: str) -> List[Dict[str, Any]]:
        """Extract findings from task result."""
        # Simple simulation - in real implementation, this would parse actual tool output
        findings = []
        if "found" in result.lower() or "discovered" in result.lower():
            findings.append({
                "type": "simulated_finding",
                "severity": "medium",
                "description": "Simulated security finding",
                "confidence": 0.8
            })
        return findings

    def _extract_artifacts_from_result(self, result: str, run_id: str, task_id: str) -> Dict[str, str]:
        """Extract artifacts from task result."""
        # Create artifact file
        artifact_dir = Path(self.settings.artifacts.dir)
        artifact_dir.mkdir(exist_ok=True)
        
        artifact_path = artifact_dir / f"{run_id}_{task_id}_result.txt"
        try:
            with open(artifact_path, 'w') as f:
                f.write(result)
            return {"task_output": str(artifact_path)}
        except Exception as e:
            logger.error(f"Failed to create artifact: {str(e)}")
            return {}

    def _generate_recommendations(self, findings: List[Dict[str, Any]]) -> List[str]:
        """Generate recommendations based on findings."""
        recommendations = []
        for finding in findings:
            if finding.get("severity") == "high":
                recommendations.append("Immediate remediation required")
            elif finding.get("severity") == "medium":
                recommendations.append("Schedule remediation within 30 days")
        return recommendations

    def _calculate_confidence_score(self, findings: List[Dict[str, Any]]) -> float:
        """Calculate confidence score for results."""
        if not findings:
            return 1.0
        
        total_confidence = sum(f.get("confidence", 0.5) for f in findings)
        return total_confidence / len(findings)

    def _estimate_memory_usage(self) -> float:
        """Estimate memory usage for the task."""
        # Simplified estimation
        return 64.0  # MB

    def _estimate_cpu_usage(self) -> float:
        """Estimate CPU usage for the task."""
        # Simplified estimation
        return 25.0  # Percent

    def _count_network_requests(self, result: str) -> int:
        """Count network requests made during task execution."""
        # Simplified counting
        return 1 if "network" in result.lower() else 0

    def _count_file_operations(self, result: str) -> int:
        """Count file operations during task execution."""
        # Simplified counting
        return 1  # At least one file operation for output

    async def get_enhanced_run_analytics(self, run_id: str) -> Dict[str, Any]:
        """Get comprehensive analytics for a run."""
        base_status = self.get_run_status(run_id)
        if not base_status:
            return {}
        
        # Get enhanced data from OpenSearch
        agent_data = {}
        for agent_name, agent_context in self.agent_contexts.items():
            agent_dashboard = await self.enhanced_logger.get_agent_dashboard_data(
                agent_context.agent_id, "24h"
            )
            agent_data[agent_name] = agent_dashboard
        
        return {
            "basic_status": base_status,
            "enhanced_analytics": {
                "agent_performance": agent_data,
                "security_events": await self._get_security_events_for_run(run_id),
                "performance_metrics": await self._get_performance_metrics_for_run(run_id),
                "quality_metrics": await self._get_quality_metrics_for_run(run_id)
            },
            "generated_at": datetime.utcnow().isoformat()
        }

    async def _get_security_events_for_run(self, run_id: str) -> List[Dict[str, Any]]:
        """Get security events for a specific run."""
        query = {
            "query": {"term": {"run_id.keyword": run_id}},
            "sort": [{"occurred_at": {"order": "desc"}}],
            "size": 100
        }
        
        return await self.enhanced_logger.client.search_documents(
            self.enhanced_logger.index_security_events, query
        )

    async def _get_performance_metrics_for_run(self, run_id: str) -> Dict[str, Any]:
        """Get performance metrics for a specific run."""
        query = {
            "query": {"term": {"run_id.keyword": run_id}},
            "aggs": {
                "avg_execution_time": {"avg": {"field": "execution_time_ms"}},
                "total_findings": {"sum": {"field": "findings_count"}},
                "avg_confidence": {"avg": {"field": "confidence_score"}}
            }
        }
        
        activities = await self.enhanced_logger.client.search_documents(
            self.enhanced_logger.index_agent_activities, query
        )
        
        if not activities:
            return {}
        
        return {
            "total_activities": len(activities),
            "average_execution_time": statistics.mean([a["execution_time_ms"] for a in activities]),
            "total_findings": sum(a["findings_count"] for a in activities),
            "average_confidence": statistics.mean([a.get("confidence_score", 0) or 0 for a in activities])
        }

    async def _get_quality_metrics_for_run(self, run_id: str) -> Dict[str, Any]:
        """Get quality metrics for a specific run."""
        query = {
            "query": {"term": {"run_id.keyword": run_id}},
            "size": 1000
        }
        
        activities = await self.enhanced_logger.client.search_documents(
            self.enhanced_logger.index_agent_activities, query
        )
        
        if not activities:
            return {}
        
        success_count = len([a for a in activities if a["status"] == "success"])
        error_count = len([a for a in activities if a["status"] == "error"])
        
        return {
            "success_rate": success_count / len(activities) if activities else 0,
            "error_rate": error_count / len(activities) if activities else 0,
            "total_tasks": len(activities),
            "successful_tasks": success_count,
            "failed_tasks": error_count
        }

    async def health_check(self) -> Dict[str, Any]:
        """Enhanced health check including logging system."""
        base_health = await super().health_check()
        
        enhanced_health = await self.enhanced_logger.health_check()
        
        return {
            **base_health,
            "enhanced_logging_healthy": enhanced_health,
            "agent_contexts_loaded": len(self.agent_contexts),
            "enhanced_features": [
                "comprehensive_agent_tracking",
                "detailed_task_monitoring",
                "security_event_logging",
                "performance_analytics",
                "quality_metrics"
            ]
        }


# Factory function
async def create_enhanced_crew_executor(settings: Settings) -> EnhancedCrewExecutor:
    """Create enhanced crew executor with logging setup."""
    from .enhanced_logger import setup_enhanced_opensearch_logger
    
    enhanced_logger = await setup_enhanced_opensearch_logger(settings)
    return EnhancedCrewExecutor(settings, enhanced_logger)
