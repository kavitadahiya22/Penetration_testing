"""Pentesting execution engine."""

import asyncio
import uuid
from datetime import datetime
from typing import Any, Dict, List

import structlog

from .config import Settings
from .logger import OpenSearchLogger
from ..tools import (
    AmassAgent,
    HydraAgent,
    NiktoAgent,
    NmapAgent,
    SQLMapAgent,
    ZAPAgent,
    generate_step_id,
)

logger = structlog.get_logger(__name__)


class PentestExecutor:
    """Orchestrates multi-step pentesting runs."""

    def __init__(self, settings: Settings, opensearch_logger: OpenSearchLogger):
        """Initialize the executor."""
        self.settings = settings
        self.opensearch_logger = opensearch_logger
        self._active_runs = {}
        
        # Initialize tool agents
        self.agents = {
            "nmap": NmapAgent(self.settings, opensearch_logger),
            "amass": AmassAgent(self.settings, opensearch_logger),
            "nikto": NiktoAgent(self.settings, opensearch_logger),
            "sqlmap": SQLMapAgent(self.settings, opensearch_logger),
            "hydra": HydraAgent(self.settings, opensearch_logger),
            "zap": ZAPAgent(self.settings, opensearch_logger),
        }

    async def execute_plan(
        self,
        plan: Dict[str, Any],
        tenant_id: str,
        simulate: bool = True
    ) -> str:
        """Execute a pentesting plan."""
        run_id = str(uuid.uuid4())
        started_at = datetime.utcnow()
        
        logger.info(
            "Starting pentesting run",
            run_id=run_id,
            plan_id=plan.get("plan_id"),
            tenant_id=tenant_id,
            steps_count=len(plan.get("steps", [])),
            simulate=simulate
        )

        # Store run status
        self._active_runs[run_id] = {
            "status": "running",
            "started_at": started_at,
            "plan": plan,
            "tenant_id": tenant_id,
            "simulate": simulate,
            "completed_steps": 0,
            "total_steps": len(plan.get("steps", [])),
            "artifacts": []
        }

        # Execute steps asynchronously
        asyncio.create_task(self._execute_steps(run_id, plan, tenant_id, simulate))
        
        return run_id

    async def _execute_steps(
        self,
        run_id: str,
        plan: Dict[str, Any],
        tenant_id: str,
        simulate: bool
    ) -> None:
        """Execute plan steps sequentially."""
        started_at = datetime.utcnow()
        steps = plan.get("steps", [])
        total_findings = 0
        max_severity = "info"
        all_artifacts = []

        try:
            for i, step in enumerate(steps):
                step_result = await self._execute_step(
                    step=step,
                    run_id=run_id,
                    tenant_id=tenant_id,
                    simulate=simulate
                )

                # Log action to OpenSearch
                await self.opensearch_logger.log_action(
                    run_id=run_id,
                    step_id=step_result["step_id"],
                    tenant_id=tenant_id,
                    agent=step_result["agent"],
                    tool=step_result["tool"],
                    status=step_result["status"],
                    params=step_result["params"],
                    summary=step_result["summary"],
                    artifacts=step_result["artifacts"],
                    started_at=datetime.fromisoformat(step_result["started_at"]),
                    ended_at=datetime.fromisoformat(step_result["ended_at"]),
                    duration_ms=step_result["duration_ms"],
                    error_message=step_result["summary"].get("error")
                )

                # Update progress
                self._active_runs[run_id]["completed_steps"] = i + 1

                # Aggregate findings
                if "total_findings" in step_result["summary"]:
                    total_findings += step_result["summary"]["total_findings"]

                # Track artifacts
                for artifact_path in step_result["artifacts"].values():
                    all_artifacts.append(artifact_path)

                # Determine severity
                step_severity = self._determine_severity(step_result["summary"])
                if self._severity_level(step_severity) > self._severity_level(max_severity):
                    max_severity = step_severity

            # Mark run as completed
            ended_at = datetime.utcnow()
            duration_ms = int((ended_at - started_at).total_seconds() * 1000)
            
            self._active_runs[run_id]["status"] = "completed"
            self._active_runs[run_id]["ended_at"] = ended_at
            self._active_runs[run_id]["artifacts"] = all_artifacts

            # Log run completion to OpenSearch
            await self.opensearch_logger.log_run(
                run_id=run_id,
                tenant_id=tenant_id,
                status="completed",
                steps_count=len(steps),
                total_findings=total_findings,
                severity=max_severity,
                started_at=started_at,
                ended_at=ended_at,
                duration_ms=duration_ms,
                artifacts=all_artifacts,
                plan_id=plan.get("plan_id", ""),
                features=self._extract_features_from_plan(plan),
                depth=self._extract_depth_from_plan(plan),
                simulate=simulate
            )

            logger.info(
                "Completed pentesting run",
                run_id=run_id,
                duration_ms=duration_ms,
                total_findings=total_findings,
                severity=max_severity
            )

        except Exception as e:
            # Mark run as failed
            ended_at = datetime.utcnow()
            duration_ms = int((ended_at - started_at).total_seconds() * 1000)
            
            self._active_runs[run_id]["status"] = "error"
            self._active_runs[run_id]["ended_at"] = ended_at
            self._active_runs[run_id]["error"] = str(e)

            # Log run failure to OpenSearch
            await self.opensearch_logger.log_run(
                run_id=run_id,
                tenant_id=tenant_id,
                status="error",
                steps_count=len(steps),
                total_findings=total_findings,
                severity="high",  # Errors are high severity
                started_at=started_at,
                ended_at=ended_at,
                duration_ms=duration_ms,
                artifacts=all_artifacts,
                plan_id=plan.get("plan_id", ""),
                features=self._extract_features_from_plan(plan),
                depth=self._extract_depth_from_plan(plan),
                simulate=simulate
            )

            logger.error("Pentesting run failed", run_id=run_id, error=str(e))

    async def _execute_step(
        self,
        step: Dict[str, Any],
        run_id: str,
        tenant_id: str,
        simulate: bool
    ) -> Dict[str, Any]:
        """Execute a single pentesting step."""
        step_id = step.get("id", generate_step_id())
        agent = step.get("agent")
        tool = step.get("tool")
        params = step.get("params", {})

        logger.info(
            "Executing step",
            run_id=run_id,
            step_id=step_id,
            agent=agent,
            tool=tool,
            simulate=simulate
        )

        # Route to appropriate tool
        try:
            if tool == "nmap":
                result = await self.agents["nmap"].scan(
                    target=params.get("target", ""),
                    profile=params.get("profile", "-sV -T4"),
                    artifacts_dir=self.settings.artifacts.dir,
                    run_id=run_id,
                    step_id=step_id,
                    allowed_networks=self.settings.policy.allow_networks,
                    max_host_count=self.settings.policy.max_host_count,
                    simulate=simulate
                )
            elif tool == "amass":
                result = await self.agents["amass"].enum_passive(
                    domain=params.get("domain", ""),
                    mode=params.get("mode", "passive"),
                    artifacts_dir=self.settings.artifacts.dir,
                    run_id=run_id,
                    step_id=step_id,
                    simulate=simulate
                )
            elif tool == "nikto":
                result = await self.agents["nikto"].scan(
                    target=params.get("host", ""),
                    artifacts_dir=self.settings.artifacts.dir,
                    run_id=run_id,
                    step_id=step_id,
                    simulate=simulate
                )
            elif tool == "sqlmap":
                result = await self.agents["sqlmap"].test(
                    url=params.get("url", ""),
                    risk=params.get("risk", 1),
                    level=params.get("level", 1),
                    artifacts_dir=self.settings.artifacts.dir,
                    run_id=run_id,
                    step_id=step_id,
                    simulate=simulate
                )
            elif tool == "hydra":
                result = await self.agents["hydra"].bruteforce(
                    users=params.get("users", []),
                    wordlist=params.get("wordlist", ""),
                    hosts=params.get("hosts", []),
                    service=params.get("service", "ssh"),
                    artifacts_dir=self.settings.artifacts.dir,
                    run_id=run_id,
                    step_id=step_id,
                    simulate=simulate,
                    exploit_simulation=self.settings.policy.exploit_simulation
                )
            elif tool == "zap":
                result = await self.agents["zap"].baseline_scan(
                    target=params.get("target", ""),
                    artifacts_dir=self.settings.artifacts.dir,
                    run_id=run_id,
                    step_id=step_id,
                    simulate=simulate
                )
            else:
                # Unsupported tool - return placeholder result
                result = {
                    "status": "error",
                    "agent": agent,
                    "tool": tool,
                    "params": params,
                    "summary": {"error": f"Unsupported tool: {tool}"},
                    "artifacts": {},
                    "started_at": datetime.utcnow().isoformat(),
                    "ended_at": datetime.utcnow().isoformat(),
                    "duration_ms": 0
                }

            # Ensure step_id is set
            result["step_id"] = step_id
            return result

        except Exception as e:
            logger.error("Step execution failed", step_id=step_id, tool=tool, error=str(e))
            return {
                "status": "error",
                "agent": agent,
                "tool": tool,
                "params": params,
                "summary": {"error": str(e)},
                "artifacts": {},
                "started_at": datetime.utcnow().isoformat(),
                "ended_at": datetime.utcnow().isoformat(),
                "duration_ms": 0,
                "step_id": step_id
            }

    def get_run_status(self, run_id: str) -> Dict[str, Any]:
        """Get status of a running pentesting operation."""
        if run_id not in self._active_runs:
            return None

        run_info = self._active_runs[run_id]
        return {
            "run_id": run_id,
            "status": run_info["status"],
            "progress": {
                "current": run_info["completed_steps"],
                "total": run_info["total_steps"]
            },
            "artifacts": run_info.get("artifacts", [])
        }

    def _determine_severity(self, summary: Dict[str, Any]) -> str:
        """Determine severity based on step summary."""
        if "error" in summary:
            return "high"
        
        # Check for high-impact findings
        if summary.get("total_findings", 0) > 10:
            return "high"
        elif summary.get("total_findings", 0) > 5:
            return "medium"
        elif summary.get("total_findings", 0) > 0:
            return "low"
        else:
            return "info"

    def _severity_level(self, severity: str) -> int:
        """Convert severity to numeric level for comparison."""
        levels = {"info": 0, "low": 1, "medium": 2, "high": 3, "critical": 4}
        return levels.get(severity, 0)

    def _extract_features_from_plan(self, plan: Dict[str, Any]) -> List[str]:
        """Extract unique features from plan steps."""
        features = set()
        for step in plan.get("steps", []):
            agent = step.get("agent")
            if agent:
                features.add(agent)
        return list(features)

    def _extract_depth_from_plan(self, plan: Dict[str, Any]) -> str:
        """Extract depth from plan based on step count."""
        step_count = len(plan.get("steps", []))
        if step_count <= 4:
            return "quick"
        elif step_count <= 8:
            return "standard"
        else:
            return "deep"
