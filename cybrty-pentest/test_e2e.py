#!/usr/bin/env python3
"""
End-to-End Testing Suite for Cybrty Pentest Platform
Tests everything from API requests to OpenSearch logging and AI model integration.
"""

import requests
import json
import time
import sys
from datetime import datetime
from typing import Dict, Any


class CybrtyE2ETester:
    def __init__(self):
        self.api_base = "http://localhost:8080"
        self.opensearch_base = "http://localhost:9200"
        self.dashboards_base = "http://localhost:5601"
        self.ollama_base = "http://localhost:11434"
        
        self.test_results = []
        
    def log_test(self, test_name: str, status: str, details: Any = None):
        """Log test results."""
        result = {
            "test": test_name,
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "details": details
        }
        self.test_results.append(result)
        
        emoji = "‚úÖ" if status == "PASS" else "‚ùå" if status == "FAIL" else "‚ö†Ô∏è"
        print(f"{emoji} {test_name}: {status}")
        if details and status != "PASS":
            print(f"   Details: {details}")
    
    def test_service_health(self):
        """Test 1: Basic service health checks."""
        print("\nüîç Testing Service Health...")
        
        # Test API Health
        try:
            response = requests.get(f"{self.api_base}/api/v1/health", timeout=10)
            if response.status_code == 200:
                data = response.json()
                self.log_test("API Health", "PASS", data)
            else:
                self.log_test("API Health", "FAIL", f"Status: {response.status_code}")
        except Exception as e:
            self.log_test("API Health", "FAIL", str(e))
        
        # Test OpenSearch Health
        try:
            response = requests.get(f"{self.opensearch_base}/_cluster/health", timeout=10)
            if response.status_code == 200:
                data = response.json()
                self.log_test("OpenSearch Health", "PASS", f"Status: {data.get('status')}")
            else:
                self.log_test("OpenSearch Health", "FAIL", f"Status: {response.status_code}")
        except Exception as e:
            self.log_test("OpenSearch Health", "FAIL", str(e))
        
        # Test Ollama Health
        try:
            response = requests.get(f"{self.ollama_base}/api/version", timeout=10)
            if response.status_code == 200:
                data = response.json()
                self.log_test("Ollama Health", "PASS", f"Version: {data.get('version')}")
            else:
                self.log_test("Ollama Health", "FAIL", f"Status: {response.status_code}")
        except Exception as e:
            self.log_test("Ollama Health", "FAIL", str(e))
    
    def test_ai_model_status(self):
        """Test 2: AI Model Configuration."""
        print("\nü§ñ Testing AI Model Status...")
        
        try:
            response = requests.get(f"{self.api_base}/api/v1/models/status", timeout=15)
            if response.status_code == 200:
                data = response.json()
                ollama_status = data.get("ollama", {})
                
                if ollama_status.get("running"):
                    models = ollama_status.get("models", [])
                    if "deepseek-coder:latest" in models:
                        self.log_test("AI Model Configuration", "PASS", f"Models: {models}")
                    else:
                        self.log_test("AI Model Configuration", "WARN", f"DeepSeek not found. Available: {models}")
                else:
                    self.log_test("AI Model Configuration", "FAIL", "Ollama not running")
            else:
                self.log_test("AI Model Configuration", "FAIL", f"Status: {response.status_code}")
        except Exception as e:
            self.log_test("AI Model Configuration", "FAIL", str(e))
    
    def test_ai_plan_generation(self):
        """Test 3: AI-Powered Plan Generation."""
        print("\nüß† Testing AI Plan Generation...")
        
        try:
            payload = {
                "targets": ["192.168.1.100"],
                "depth": "standard",
                "features": ["recon", "web", "vuln"],
                "simulate": True,
                "tenant_id": "test-tenant-001"
            }
            
            response = requests.post(
                f"{self.api_base}/api/v1/agents/pentest/plan",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                plan_id = data.get("plan_id")
                steps = data.get("steps", [])
                
                if plan_id and steps:
                    self.log_test("AI Plan Generation", "PASS", f"Plan ID: {plan_id}, Steps: {len(steps)}")
                    return plan_id
                else:
                    self.log_test("AI Plan Generation", "FAIL", "No plan ID or steps returned")
            else:
                self.log_test("AI Plan Generation", "FAIL", f"Status: {response.status_code}, Response: {response.text}")
        except Exception as e:
            self.log_test("AI Plan Generation", "FAIL", str(e))
        
        return None
    
    def test_opensearch_logging(self):
        """Test 4: OpenSearch Index Creation and Logging."""
        print("\nüìä Testing OpenSearch Logging...")
        
        # Check if indices exist
        try:
            indices_to_check = ["cybrty-actions", "cybrty-planner", "cybrty-runs"]
            
            for index in indices_to_check:
                try:
                    response = requests.get(f"{self.opensearch_base}/{index}/_count", timeout=10)
                    if response.status_code == 200:
                        data = response.json()
                        count = data.get("count", 0)
                        self.log_test(f"OpenSearch Index: {index}", "PASS", f"Documents: {count}")
                    else:
                        self.log_test(f"OpenSearch Index: {index}", "WARN", "Index may not exist yet")
                except Exception as e:
                    self.log_test(f"OpenSearch Index: {index}", "WARN", "Index not created yet")
        
        except Exception as e:
            self.log_test("OpenSearch Logging", "FAIL", str(e))
    
    def test_model_switching(self):
        """Test 5: AI Model Switching Capability."""
        print("\nüîÑ Testing Model Switching...")
        
        try:
            # Test switching to a different model (if available)
            payload = {
                "provider": "ollama",
                "model_name": "deepseek-coder"
            }
            
            response = requests.post(
                f"{self.api_base}/api/v1/models/switch",
                json=payload,
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                self.log_test("Model Switching", "PASS", f"Active model: {data.get('model_name')}")
            else:
                self.log_test("Model Switching", "FAIL", f"Status: {response.status_code}")
        except Exception as e:
            self.log_test("Model Switching", "FAIL", str(e))
    
    def test_dashboard_access(self):
        """Test 6: Dashboard Accessibility."""
        print("\nüìà Testing Dashboard Access...")
        
        try:
            response = requests.get(self.dashboards_base, timeout=10)
            if response.status_code == 200:
                self.log_test("Dashboard Access", "PASS", "Dashboards accessible")
            else:
                self.log_test("Dashboard Access", "FAIL", f"Status: {response.status_code}")
        except Exception as e:
            self.log_test("Dashboard Access", "FAIL", str(e))
    
    def test_simulation_mode(self):
        """Test 7: Simulation Mode Execution."""
        print("\nüéØ Testing Simulation Mode...")
        
        try:
            payload = {
                "tenant_id": "test-tenant-001",
                "inputs": {
                    "targets": ["192.168.1.100"],
                    "depth": "quick",
                    "features": ["recon"],
                    "simulate": True
                }
            }
            
            response = requests.post(
                f"{self.api_base}/api/v1/agents/pentest/run",
                json=payload,
                timeout=45
            )
            
            if response.status_code == 200:
                data = response.json()
                run_id = data.get("run_id")
                if run_id:
                    self.log_test("Simulation Mode", "PASS", f"Run ID: {run_id}")
                    return run_id
                else:
                    self.log_test("Simulation Mode", "FAIL", "No run ID returned")
            else:
                self.log_test("Simulation Mode", "FAIL", f"Status: {response.status_code}, Response: {response.text}")
        except Exception as e:
            self.log_test("Simulation Mode", "FAIL", str(e))
        
        return None
    
    def generate_report(self):
        """Generate final test report."""
        print("\n" + "="*50)
        print("üìã CYBRTY PENTEST PLATFORM - E2E TEST REPORT")
        print("="*50)
        
        passed = len([r for r in self.test_results if r["status"] == "PASS"])
        failed = len([r for r in self.test_results if r["status"] == "FAIL"])
        warnings = len([r for r in self.test_results if r["status"] == "WARN"])
        total = len(self.test_results)
        
        print(f"Total Tests: {total}")
        print(f"‚úÖ Passed: {passed}")
        print(f"‚ùå Failed: {failed}")
        print(f"‚ö†Ô∏è  Warnings: {warnings}")
        print(f"Success Rate: {(passed/total)*100:.1f}%")
        
        print("\nüîó Access URLs:")
        print(f"API:        {self.api_base}")
        print(f"Dashboards: {self.dashboards_base}")
        print(f"OpenSearch: {self.opensearch_base}")
        print(f"Ollama:     {self.ollama_base}")
        
        print("\nüìù Ready for Manual Testing:")
        print("1. Generate AI pentest plan: POST /api/v1/agents/pentest/plan")
        print("2. Run simulation tests: POST /api/v1/agents/pentest/run")
        print("3. View analytics: GET /api/v1/analytics/dashboard")
        print("4. Check model status: GET /api/v1/models/status")
        print("5. Switch AI models: POST /api/v1/models/switch")
        
        return passed == total

def main():
    """Run complete end-to-end test suite."""
    print("üöÄ Starting Cybrty Pentest Platform E2E Tests...")
    print(f"‚è∞ Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    tester = CybrtyE2ETester()
    
    # Run all tests
    tester.test_service_health()
    tester.test_ai_model_status()
    tester.test_ai_plan_generation()
    tester.test_opensearch_logging()
    tester.test_model_switching()
    tester.test_dashboard_access()
    tester.test_simulation_mode()
    
    # Generate report
    success = tester.generate_report()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
